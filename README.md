# Product Development - PredicciÃ³n de Ventas

<a target="_blank" href="https://cookiecutter-data-science.drivendata.org/">
    <img src="https://img.shields.io/badge/CCDS-Project%20template-328F97?logo=cookiecutter" />
</a>

[![Python 3.11](https://img.shields.io/badge/python-3.11-blue.svg)](https://www.python.org/downloads/release/python-3110/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

**Proyecto del Curso - Pipeline de MLOps para PredicciÃ³n de Ventas**

---

## ğŸ“‹ DescripciÃ³n

Este proyecto implementa un **pipeline completo de MLOps** para la predicciÃ³n de ventas utilizando tÃ©cnicas de machine learning. El sistema estÃ¡ diseÃ±ado siguiendo las mejores prÃ¡cticas de ciencia de datos e ingenierÃ­a de software, incluyendo:

- âœ… AnÃ¡lisis exploratorio de datos (EDA)
- âœ… IngenierÃ­a de caracterÃ­sticas automatizada
- âœ… Entrenamiento y selecciÃ³n de modelos
- âœ… Pipeline de inferencia reproducible
- âœ… Arquitectura modular y escalable
- âœ… **API REST** para predicciones en tiempo real
- âœ… **MLflow** para tracking de experimentos y model registry

---

## ğŸ¯ Objetivo del Proyecto

Desarrollar un sistema de predicciÃ³n de ventas que permita:
1. Procesar datos histÃ³ricos de ventas por tienda y artÃ­culo
2. Generar caracterÃ­sticas predictivas automÃ¡ticamente
3. Entrenar y evaluar mÃºltiples modelos de machine learning
4. Producir predicciones confiables para la planificaciÃ³n de inventario

---

## ğŸ“ OrganizaciÃ³n del Proyecto

```
product_development/
â”‚
â”œâ”€â”€ ğŸ“„ LICENSE                 <- Licencia de cÃ³digo abierto (MIT)
â”œâ”€â”€ ğŸ“„ Makefile                <- Comandos Ãºtiles (make data, make train, etc.)
â”œâ”€â”€ ğŸ“„ README.md               <- DocumentaciÃ³n principal del proyecto
â”œâ”€â”€ ğŸ“„ pyproject.toml          <- ConfiguraciÃ³n del proyecto y dependencias
â”œâ”€â”€ ğŸ“„ environment.yml         <- Entorno conda con todas las dependencias
â”‚
â”œâ”€â”€ ğŸ“‚ data/                   <- Datos del proyecto
â”‚   â”œâ”€â”€ external/              <- Datos de fuentes externas
â”‚   â”œâ”€â”€ processed/             <- Datos procesados listos para modelado
â”‚   â”‚   â”œâ”€â”€ preproc_train.csv  <- Dataset preprocesado
â”‚   â”‚   â””â”€â”€ test_predictions.csv <- Predicciones generadas
â”‚   â””â”€â”€ raw/                   <- Datos originales (inmutables)
â”‚       â””â”€â”€ train.csv          <- Dataset de entrenamiento (date, store, item, sales)
â”‚
â”œâ”€â”€ ğŸ“‚ docs/                   <- DocumentaciÃ³n adicional del proyecto
â”‚
â”œâ”€â”€ ğŸ“‚ models/                 <- Modelos entrenados serializados
â”‚   â”œâ”€â”€ feature_engineering_pipeline.pkl  <- Pipeline de ingenierÃ­a de caracterÃ­sticas
â”‚   â””â”€â”€ sales_pipeline.pkl                <- Pipeline completo de predicciÃ³n
â”‚
â”œâ”€â”€ ğŸ“‚ mlruns/                 <- Directorio de MLflow para tracking
â”‚   â””â”€â”€ ...                    <- Experimentos, mÃ©tricas y artefactos
â”‚
â”œâ”€â”€ ğŸ“‚ notebooks/              <- Jupyter notebooks del flujo de trabajo
â”‚   â”œâ”€â”€ 01_Data_Exploration.ipynb      <- EDA: anÃ¡lisis y visualizaciones
â”‚   â”œâ”€â”€ 02_feature_exploration.ipynb   <- ExploraciÃ³n de caracterÃ­sticas
â”‚   â”œâ”€â”€ 03_feature_creation.ipynb      <- CreaciÃ³n de features con sklearn
â”‚   â”œâ”€â”€ 04_model_tuning_training.ipynb <- Ajuste y entrenamiento de modelos
â”‚   â”œâ”€â”€ 05_inference_calculation.ipynb <- CÃ¡lculo de predicciones
â”‚   â””â”€â”€ operators.py                   <- Transformadores para notebooks
â”‚
â”œâ”€â”€ ğŸ“‚ references/             <- Diccionarios de datos y materiales de referencia
â”‚
â”œâ”€â”€ ğŸ“‚ reports/                <- Reportes y anÃ¡lisis generados
â”‚   â””â”€â”€ figures/               <- GrÃ¡ficos y figuras para reportes
â”‚
â”œâ”€â”€ ğŸ“‚ tests/                  <- Pruebas unitarias
â”‚   â”œâ”€â”€ test_data.py           <- Tests de validaciÃ³n de datos
â”‚   â””â”€â”€ test_api_examples.py   <- Ejemplos de consumo de la API
â”‚
â”œâ”€â”€ ğŸ“‚ scripts/                <- Scripts auxiliares
â”‚   â””â”€â”€ run_api_simple.py      <- Script simple para ejecutar la API
â”‚
â””â”€â”€ ğŸ“‚ product_development/    <- ğŸ“¦ CÃ³digo fuente del paquete
    â”‚
    â”œâ”€â”€ __init__.py            <- InicializaciÃ³n del mÃ³dulo Python
    â”œâ”€â”€ config.py              <- ConfiguraciÃ³n de rutas y constantes
    â”œâ”€â”€ dataset.py             <- Funciones de carga y preparaciÃ³n de datos
    â”œâ”€â”€ features.py            <- Pipeline de ingenierÃ­a de caracterÃ­sticas
    â”œâ”€â”€ plots.py               <- Funciones de visualizaciÃ³n
    â”œâ”€â”€ transformers.py        <- Transformadores personalizados de sklearn
    â”œâ”€â”€ run_pipeline.py        <- Script principal del pipeline MLOps
    â”œâ”€â”€ api.py                 <- ğŸŒ API REST Flask para predicciones
    â”œâ”€â”€ run_api.py             <- Script para ejecutar la API
    â”‚
    â””â”€â”€ modeling/              <- SubmÃ³dulo de modelado
        â”œâ”€â”€ __init__.py
        â”œâ”€â”€ train.py           <- Entrenamiento y evaluaciÃ³n de modelos
        â””â”€â”€ predict.py         <- Inferencia y generaciÃ³n de predicciones
```

---

## ğŸ”„ Flujo de Trabajo

El proyecto sigue un flujo de trabajo estructurado en 5 etapas:

### 1ï¸âƒ£ ExploraciÃ³n de Datos
**Notebook:** `01_Data_Exploration.ipynb`

- AnÃ¡lisis exploratorio del dataset de ventas
- EstadÃ­sticas descriptivas por tienda y artÃ­culo
- Visualizaciones de series temporales
- IdentificaciÃ³n de patrones y tendencias

### 2ï¸âƒ£ ExploraciÃ³n de CaracterÃ­sticas
**Notebook:** `02_feature_exploration.ipynb`

- AnÃ¡lisis de correlaciones
- EvaluaciÃ³n de variables candidatas
- SelecciÃ³n de caracterÃ­sticas relevantes

### 3ï¸âƒ£ CreaciÃ³n de CaracterÃ­sticas
**Notebook:** `03_feature_creation.ipynb`

Pipeline de ingenierÃ­a de caracterÃ­sticas que incluye:
- ğŸ“Š **Features de Lag**: 1, 7, 14, 28 dÃ­as
- ğŸ“ˆ **Medias MÃ³viles**: ventanas de 7 y 28 dÃ­as
- ğŸ·ï¸ **CodificaciÃ³n de Frecuencia**: para tiendas e items
- ğŸ“… **Features Temporales**: aÃ±o, mes, dÃ­a de la semana
- âš–ï¸ **Escalado MinMax**: normalizaciÃ³n de caracterÃ­sticas

### 4ï¸âƒ£ Entrenamiento del Modelo
**Notebook:** `04_model_tuning_training.ipynb`

EvaluaciÃ³n de mÃºltiples algoritmos:
- RegresiÃ³n Lineal
- Random Forest
- Gradient Boosting
- Support Vector Regression (SVR)
- XGBoost

### 5ï¸âƒ£ Inferencia
**Notebook:** `05_inference_calculation.ipynb`

- Carga del pipeline entrenado
- GeneraciÃ³n de predicciones
- EvaluaciÃ³n de mÃ©tricas (RMSE)

---

## ğŸŒ API REST

El proyecto incluye una **API REST** construida con Flask para realizar predicciones en tiempo real.

### Iniciar la API

```bash
# OpciÃ³n 1: Usando el mÃ³dulo principal
python -m product_development.run_api

# OpciÃ³n 2: Con opciones personalizadas
python -m product_development.run_api --host 0.0.0.0 --port 5000 --debug

# OpciÃ³n 3: Script simple (sin dependencias adicionales)
python scripts/run_api_simple.py
```

### Endpoints Disponibles

| Endpoint | MÃ©todo | DescripciÃ³n |
|----------|--------|-------------|
| `/` | GET | InformaciÃ³n de la API |
| `/health` | GET | Health check del servicio |
| `/model/info` | GET | InformaciÃ³n del modelo (mÃ©tricas, hiperparÃ¡metros) |
| `/predict` | POST | PredicciÃ³n individual |
| `/predict/batch` | POST | PredicciÃ³n por lote |

### Ejemplos de Uso

#### PredicciÃ³n Individual

```bash
curl -X POST http://localhost:5000/predict \
  -H "Content-Type: application/json" \
  -d '{"store": 1, "item": 1, "date": "2018-01-15"}'
```

**Respuesta:**
```json
{
  "predictions": [42.35],
  "model_metrics": {"rmse": 13.08, "mae": 10.25, "r2": 0.91},
  "timestamp": "2024-01-15T10:30:00",
  "prediction_count": 1
}
```

#### PredicciÃ³n por Lote (Batch)

```bash
curl -X POST http://localhost:5000/predict/batch \
  -H "Content-Type: application/json" \
  -d '{
    "data": [
      {"store": 1, "item": 1, "date": "2018-01-15"},
      {"store": 2, "item": 3, "date": "2018-01-16"},
      {"store": 5, "item": 10, "date": "2018-02-01"}
    ]
  }'
```

#### Usando Python

```python
import requests

# PredicciÃ³n individual
response = requests.post(
    "http://localhost:5000/predict",
    json={"store": 1, "item": 1, "date": "2018-01-15"}
)
print(response.json())

# PredicciÃ³n batch
response = requests.post(
    "http://localhost:5000/predict/batch",
    json={
        "data": [
            {"store": 1, "item": 1, "date": "2018-01-15"},
            {"store": 2, "item": 3, "date": "2018-01-16"}
        ]
    }
)
print(response.json())
```

### Probar la API

```bash
# Ejecutar ejemplos de prueba
python tests/test_api_examples.py
```

---

## ğŸš€ InstalaciÃ³n

### Prerrequisitos
- Python 3.11
- Conda (recomendado) o pip

### OpciÃ³n 1: Usando Conda (Recomendado)

```bash
# Clonar el repositorio
git clone https://github.com/franciscogonzalez-gal/product_development.git
cd product_development

# Crear entorno conda desde environment.yml
conda env create -f environment.yml

# Activar entorno
conda activate product_development

# Instalar el paquete en modo desarrollo
pip install -e .
```

### OpciÃ³n 2: Usando pip

```bash
# Clonar el repositorio
git clone https://github.com/franciscogonzalez-gal/product_development.git
cd product_development

# Crear entorno virtual
python -m venv venv
source venv/bin/activate  # En Windows: venv\Scripts\activate

# Instalar el paquete en modo desarrollo
pip install -e .
```

---

## ğŸ’» Uso

### Ejecutar el Pipeline Completo

```bash
# Ejecutar pipeline completo (entrenamiento + inferencia)
python -m product_development.run_pipeline

# Solo inferencia (usando modelo existente)
python -m product_development.run_pipeline --skip-training

# Especificar rutas personalizadas
python -m product_development.run_pipeline \
    --input-path data/raw/train.csv \
    --output-path data/processed/predictions.csv
```

### Opciones del Pipeline

| OpciÃ³n | DescripciÃ³n |
|--------|-------------|
| `--input-path`, `-i` | Ruta a los datos crudos de entrenamiento |
| `--output-path`, `-o` | Ruta para guardar las predicciones |
| `--skip-training`, `-s` | Omitir entrenamiento y usar pipeline existente |
| `--inference-data`, `-d` | Ruta a datos para inferencia |

### Usar como Biblioteca

```python
from product_development.dataset import load_raw_data, prepare_dataset
from product_development.features import build_feature_pipeline
from product_development.modeling.train import train_and_evaluate_models
from product_development.modeling.predict import load_and_predict

# Cargar y preparar datos
data = load_raw_data()
prepared_data = prepare_dataset(data)

# Generar predicciones con modelo existente
predictions = load_and_predict(prepared_data)
```

---

## ğŸ“Š MLflow - Tracking de Experimentos

El proyecto utiliza **MLflow** para el seguimiento de experimentos y registro de modelos.

### ConfiguraciÃ³n de MLflow

```python
# En config.py
MLFLOW_TRACKING_URI = "mlruns"           # URI del servidor de tracking
MLFLOW_EXPERIMENT_NAME = "sales_prediction"
MLFLOW_MODEL_NAME = "sales_prediction_model"
MLFLOW_CHAMPION_ALIAS = "champion"       # Alias del modelo en producciÃ³n
```

### Ver Experimentos

```bash
# Iniciar la UI de MLflow
mlflow ui --backend-store-uri mlruns

# Abrir en el navegador: http://localhost:5000
```

### CaracterÃ­sticas de MLflow en el Proyecto

- ğŸ“ˆ **Tracking de mÃ©tricas**: RMSE, MAE, RÂ², MSE
- ğŸ”§ **Registro de hiperparÃ¡metros**: ParÃ¡metros del modelo
- ğŸ“¦ **Model Registry**: GestiÃ³n de versiones de modelos
- ğŸ·ï¸ **Aliases**: Champion/Challenger para promociÃ³n de modelos

---

## ğŸ› ï¸ TecnologÃ­as Utilizadas

| CategorÃ­a | TecnologÃ­as |
|-----------|-------------|
| **Lenguaje** | Python 3.11 |
| **ManipulaciÃ³n de Datos** | Pandas, NumPy |
| **Machine Learning** | Scikit-learn, XGBoost |
| **IngenierÃ­a de CaracterÃ­sticas** | Feature-engine |
| **VisualizaciÃ³n** | Matplotlib, Seaborn |
| **AnÃ¡lisis EstadÃ­stico** | Statsmodels |
| **API REST** | Flask |
| **MLOps** | MLflow |
| **CLI** | Typer |
| **Logging** | Loguru |
| **SerializaciÃ³n** | Joblib |
| **ConfiguraciÃ³n** | python-dotenv |

---

## ğŸ“Š Estructura de Datos

### Dataset de Entrada (`train.csv`)

| Columna | Tipo | DescripciÃ³n |
|---------|------|-------------|
| `date` | datetime | Fecha de la venta |
| `store` | int | Identificador de la tienda |
| `item` | int | Identificador del artÃ­culo |
| `sales` | int | Cantidad de ventas |

### CaracterÃ­sticas Generadas

| CaracterÃ­stica | DescripciÃ³n |
|----------------|-------------|
| `year` | AÃ±o extraÃ­do de la fecha |
| `month` | Mes extraÃ­do de la fecha |
| `day_of_week_name` | Nombre del dÃ­a de la semana |
| `store` (encoded) | Tienda codificada por frecuencia |
| `item` (encoded) | ArtÃ­culo codificado por frecuencia |

---

## ğŸ§ª Pruebas

```bash
# Ejecutar todas las pruebas
pytest tests/

# Ejecutar con cobertura
pytest tests/ --cov=product_development

# Probar ejemplos de la API (requiere que la API estÃ© corriendo)
python tests/test_api_examples.py
```

---

## ğŸ“ˆ MÃ©tricas de EvaluaciÃ³n

El modelo se evalÃºa utilizando:
- **RMSE** (Root Mean Square Error): MÃ©trica principal de evaluaciÃ³n
- **MAE** (Mean Absolute Error): Error absoluto promedio
- **RÂ²** (Coeficiente de determinaciÃ³n): Varianza explicada
- **MSE** (Mean Square Error): Error cuadrÃ¡tico medio

### Resultados del Modelo

| MÃ©trica | Valor |
|---------|-------|
| RMSE | ~13.09 |
| MAE | ~10.25 |
| RÂ² | ~0.91 |

---

## ğŸ‘¥ Autores

- **Galileo Team** - Universidad Galileo

---

## ğŸ“„ Licencia

Este proyecto estÃ¡ bajo la Licencia MIT - ver el archivo [LICENSE](LICENSE) para mÃ¡s detalles.

---

## ğŸ™ Agradecimientos

- [Cookiecutter Data Science](https://cookiecutter-data-science.drivendata.org/) por la plantilla del proyecto
- Universidad Galileo por el soporte acadÃ©mico

---

<p align="center">
  <i>Desarrollado con â¤ï¸ para el curso de Desarrollo de Producto</i>
</p>