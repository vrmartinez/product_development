# Product Development - Predicci√≥n de Ventas

<a target="_blank" href="https://cookiecutter-data-science.drivendata.org/">
    <img src="https://img.shields.io/badge/CCDS-Project%20template-328F97?logo=cookiecutter" />
</a>

[![Python 3.11](https://img.shields.io/badge/python-3.11-blue.svg)](https://www.python.org/downloads/release/python-3110/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![DVC](https://img.shields.io/badge/DVC-Pipeline-945DD6?logo=dvc)](https://dvc.org/)
[![MLflow](https://img.shields.io/badge/MLflow-Tracking-0194E2?logo=mlflow)](https://mlflow.org/)

**Proyecto del Curso - Pipeline de MLOps para Predicci√≥n de Ventas**

---

## üìã Descripci√≥n

Este proyecto implementa un **pipeline completo de MLOps** para la predicci√≥n de ventas utilizando t√©cnicas de machine learning. El sistema est√° dise√±ado siguiendo las mejores pr√°cticas de ciencia de datos e ingenier√≠a de software, incluyendo:

- ‚úÖ An√°lisis exploratorio de datos (EDA)
- ‚úÖ Ingenier√≠a de caracter√≠sticas automatizada
- ‚úÖ Entrenamiento y selecci√≥n de modelos
- ‚úÖ Pipeline de inferencia reproducible
- ‚úÖ Arquitectura modular y escalable
- ‚úÖ **API REST** para predicciones en tiempo real
- ‚úÖ **MLflow** para tracking de experimentos y model registry
- ‚úÖ **DVC** para versionado de datos y pipelines reproducibles

---

## üéØ Objetivo del Proyecto

Desarrollar un sistema de predicci√≥n de ventas que permita:
1. Procesar datos hist√≥ricos de ventas por tienda y art√≠culo
2. Generar caracter√≠sticas predictivas autom√°ticamente
3. Entrenar y evaluar m√∫ltiples modelos de machine learning
4. Producir predicciones confiables para la planificaci√≥n de inventario

---

## üìÅ Organizaci√≥n del Proyecto

```
product_development/
‚îÇ
‚îú‚îÄ‚îÄ üìÑ LICENSE                 <- Licencia de c√≥digo abierto (MIT)
‚îú‚îÄ‚îÄ üìÑ Makefile                <- Comandos √∫tiles (make data, make train, etc.)
‚îú‚îÄ‚îÄ üìÑ README.md               <- Documentaci√≥n principal del proyecto
‚îú‚îÄ‚îÄ üìÑ pyproject.toml          <- Configuraci√≥n del proyecto y dependencias
‚îú‚îÄ‚îÄ üìÑ environment.yml         <- Entorno conda con todas las dependencias
‚îú‚îÄ‚îÄ üìÑ dvc.yaml                <- Definici√≥n del pipeline DVC
‚îú‚îÄ‚îÄ üìÑ params.yaml             <- Par√°metros configurables del pipeline
‚îÇ
‚îú‚îÄ‚îÄ üìÇ data/                   <- Datos del proyecto
‚îÇ   ‚îú‚îÄ‚îÄ external/              <- Datos de fuentes externas
‚îÇ   ‚îú‚îÄ‚îÄ processed/             <- Datos procesados listos para modelado
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ prepared_data.csv  <- Dataset con caracter√≠sticas temporales
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ preproc_train.csv  <- Dataset preprocesado
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ test_predictions.csv <- Predicciones generadas
‚îÇ   ‚îî‚îÄ‚îÄ raw/                   <- Datos originales (inmutables)
‚îÇ       ‚îî‚îÄ‚îÄ train.csv          <- Dataset de entrenamiento (date, store, item, sales)
‚îÇ
‚îú‚îÄ‚îÄ üìÇ docs/                   <- Documentaci√≥n adicional del proyecto
‚îÇ   ‚îî‚îÄ‚îÄ DVC_PIPELINE.md        <- Documentaci√≥n del pipeline DVC
‚îÇ
‚îú‚îÄ‚îÄ üìÇ models/                 <- Modelos entrenados serializados
‚îÇ   ‚îú‚îÄ‚îÄ feature_engineering_pipeline.pkl  <- Pipeline de ingenier√≠a de caracter√≠sticas
‚îÇ   ‚îî‚îÄ‚îÄ sales_pipeline.pkl                <- Pipeline completo de predicci√≥n
‚îÇ
‚îú‚îÄ‚îÄ üìÇ mlruns/                 <- Directorio de MLflow para tracking
‚îÇ   ‚îî‚îÄ‚îÄ ...                    <- Experimentos, m√©tricas y artefactos
‚îÇ
‚îú‚îÄ‚îÄ üìÇ notebooks/              <- Jupyter notebooks del flujo de trabajo
‚îÇ   ‚îú‚îÄ‚îÄ 01_Data_Exploration.ipynb      <- EDA: an√°lisis y visualizaciones
‚îÇ   ‚îú‚îÄ‚îÄ 02_feature_exploration.ipynb   <- Exploraci√≥n de caracter√≠sticas
‚îÇ   ‚îú‚îÄ‚îÄ 03_feature_creation.ipynb      <- Creaci√≥n de features con sklearn
‚îÇ   ‚îú‚îÄ‚îÄ 04_model_tuning_training.ipynb <- Ajuste y entrenamiento de modelos
‚îÇ   ‚îú‚îÄ‚îÄ 05_inference_calculation.ipynb <- C√°lculo de predicciones
‚îÇ   ‚îî‚îÄ‚îÄ operators.py                   <- Transformadores para notebooks
‚îÇ
‚îú‚îÄ‚îÄ üìÇ references/             <- Diccionarios de datos y materiales de referencia
‚îÇ
‚îú‚îÄ‚îÄ üìÇ reports/                <- Reportes y an√°lisis generados
‚îÇ   ‚îú‚îÄ‚îÄ metrics.json           <- M√©tricas del modelo (generado por DVC)
‚îÇ   ‚îî‚îÄ‚îÄ figures/               <- Gr√°ficos y figuras para reportes
‚îÇ
‚îú‚îÄ‚îÄ üìÇ tests/                  <- Pruebas unitarias
‚îÇ   ‚îú‚îÄ‚îÄ test_data.py           <- Tests de validaci√≥n de datos
‚îÇ   ‚îî‚îÄ‚îÄ test_api_examples.py   <- Ejemplos de consumo de la API
‚îÇ
‚îú‚îÄ‚îÄ üìÇ scripts/                <- Scripts auxiliares
‚îÇ   ‚îú‚îÄ‚îÄ dvc_train.py           <- Script de entrenamiento para DVC
‚îÇ   ‚îú‚îÄ‚îÄ dvc_inference.py       <- Script de inferencia para DVC
‚îÇ   ‚îú‚îÄ‚îÄ run_api.py             <- Script para ejecutar la API
‚îÇ   ‚îî‚îÄ‚îÄ run_pipeline.py        <- Script principal del pipeline MLOps
‚îÇ
‚îî‚îÄ‚îÄ üìÇ product_development/    <- üì¶ C√≥digo fuente del paquete
    ‚îÇ
    ‚îú‚îÄ‚îÄ __init__.py            <- Inicializaci√≥n del m√≥dulo Python
    ‚îú‚îÄ‚îÄ config.py              <- Configuraci√≥n de rutas y constantes
    ‚îú‚îÄ‚îÄ dataset.py             <- Funciones de carga y preparaci√≥n de datos
    ‚îú‚îÄ‚îÄ features.py            <- Pipeline de ingenier√≠a de caracter√≠sticas
    ‚îú‚îÄ‚îÄ plots.py               <- Funciones de visualizaci√≥n
    ‚îú‚îÄ‚îÄ transformers.py        <- Transformadores personalizados de sklearn
    ‚îú‚îÄ‚îÄ api.py                 <- üåê API REST Flask para predicciones
    ‚îÇ
    ‚îî‚îÄ‚îÄ modeling/              <- Subm√≥dulo de modelado
        ‚îú‚îÄ‚îÄ __init__.py
        ‚îú‚îÄ‚îÄ train.py           <- Entrenamiento y evaluaci√≥n de modelos
        ‚îî‚îÄ‚îÄ predict.py         <- Inferencia y generaci√≥n de predicciones
```

---

## üîÑ Flujo de Trabajo

El proyecto sigue un flujo de trabajo estructurado en 5 etapas:

### 1Ô∏è‚É£ Exploraci√≥n de Datos
**Notebook:** `01_Data_Exploration.ipynb`

- An√°lisis exploratorio del dataset de ventas
- Estad√≠sticas descriptivas por tienda y art√≠culo
- Visualizaciones de series temporales
- Identificaci√≥n de patrones y tendencias

### 2Ô∏è‚É£ Exploraci√≥n de Caracter√≠sticas
**Notebook:** `02_feature_exploration.ipynb`

- An√°lisis de correlaciones
- Evaluaci√≥n de variables candidatas
- Selecci√≥n de caracter√≠sticas relevantes

### 3Ô∏è‚É£ Creaci√≥n de Caracter√≠sticas
**Notebook:** `03_feature_creation.ipynb`

Pipeline de ingenier√≠a de caracter√≠sticas que incluye:
- üìä **Features de Lag**: 1, 7, 14, 28 d√≠as
- üìà **Medias M√≥viles**: ventanas de 7 y 28 d√≠as
- üè∑Ô∏è **Codificaci√≥n de Frecuencia**: para tiendas e items
- üìÖ **Features Temporales**: a√±o, mes, d√≠a de la semana
- ‚öñÔ∏è **Escalado MinMax**: normalizaci√≥n de caracter√≠sticas

### 4Ô∏è‚É£ Entrenamiento del Modelo
**Notebook:** `04_model_tuning_training.ipynb`

Evaluaci√≥n de m√∫ltiples algoritmos:
- Regresi√≥n Lineal
- Random Forest
- Gradient Boosting
- Support Vector Regression (SVR)
- XGBoost

### 5Ô∏è‚É£ Inferencia
**Notebook:** `05_inference_calculation.ipynb`

- Carga del pipeline entrenado
- Generaci√≥n de predicciones
- Evaluaci√≥n de m√©tricas (RMSE)

---

## üîÑ Pipeline DVC

El proyecto incluye un **pipeline DVC** para automatizar y reproducir el flujo de trabajo completo.

### Estructura del Pipeline

```
prepare_data ‚Üí feature_engineering ‚Üí train_model ‚Üí inference
```

| Etapa | Entrada | Salida | Descripci√≥n |
|-------|---------|--------|-------------|
| `prepare_data` | `data/raw/train.csv` | `data/processed/prepared_data.csv` | Carga datos y agrega features temporales |
| `feature_engineering` | `prepared_data.csv` | `feature_engineering_pipeline.pkl` | Construye pipeline de caracter√≠sticas |
| `train_model` | `prepared_data.csv`, `pipeline.pkl` | `sales_pipeline.pkl`, `metrics.json` | Entrena y eval√∫a modelos |
| `inference` | `prepared_data.csv`, `sales_pipeline.pkl` | `test_predictions.csv` | Genera predicciones |

### Comandos DVC

```bash
# Ejecutar todo el pipeline
dvc repro

# Ejecutar una etapa espec√≠fica
dvc repro train_model

# Ver estado del pipeline
dvc status

# Ver grafo de dependencias
dvc dag

# Ver m√©tricas
dvc metrics show

# Comparar m√©tricas entre experimentos
dvc metrics diff
```

### Par√°metros del Pipeline (`params.yaml`)

```yaml
# Configuraci√≥n de divisi√≥n de datos
data:
  train_test_split_ratio: 0.8    # Proporci√≥n train/test
  random_state: 2025             # Semilla para reproducibilidad

# Configuraci√≥n de caracter√≠sticas
features:
  target: "sales"
  feature_columns:
    - "store"
    - "item"
    - "year"
    - "month"
    - "day_of_week_name"
  categorical_vars:
    - "store"
    - "item"
    - "day_of_week_name"
  numerical_vars:
    - "year"
    - "month"

# Configuraci√≥n de entrenamiento
training:
  mode: "fast"                   # "fast" o "full"
  use_mlflow: true               # Registrar en MLflow

# Configuraci√≥n de MLflow
mlflow:
  tracking_uri: "mlruns"
  experiment_name: "sales_prediction"
  model_name: "sales_prediction_model"
```

> üìñ Para m√°s detalles, consulta [docs/DVC_PIPELINE.md](docs/DVC_PIPELINE.md)

---

## üåê API REST

El proyecto incluye una **API REST** construida con Flask para realizar predicciones en tiempo real.

### Iniciar la API

```bash
# Opci√≥n 1: Usando el script de scripts/
python scripts/run_api.py

# Opci√≥n 2: Con opciones personalizadas
python scripts/run_api.py --host 0.0.0.0 --port 5000 --debug

# Opci√≥n 3: Ejecutando directamente el m√≥dulo api
python -m product_development.api
```

### Endpoints Disponibles

| Endpoint | M√©todo | Descripci√≥n |
|----------|--------|-------------|
| `/` | GET | Informaci√≥n de la API |
| `/health` | GET | Health check del servicio |
| `/model/info` | GET | Informaci√≥n del modelo (m√©tricas, hiperpar√°metros) |
| `/predict` | POST | Predicci√≥n individual |
| `/predict/batch` | POST | Predicci√≥n por lote |

### Ejemplos de Uso

#### Predicci√≥n Individual

```bash
curl -X POST http://localhost:5000/predict \
  -H "Content-Type: application/json" \
  -d '{"store": 1, "item": 1, "date": "2018-01-15"}'
```

**Respuesta:**
```json
{
  "predictions": [42.35],
  "model_metrics": {"rmse": 13.08, "mae": 10.25, "r2": 0.91},
  "timestamp": "2024-01-15T10:30:00",
  "prediction_count": 1
}
```

#### Predicci√≥n por Lote (Batch)

```bash
curl -X POST http://localhost:5000/predict/batch \
  -H "Content-Type: application/json" \
  -d '{
    "data": [
      {"store": 1, "item": 1, "date": "2018-01-15"},
      {"store": 2, "item": 3, "date": "2018-01-16"},
      {"store": 5, "item": 10, "date": "2018-02-01"}
    ]
  }'
```

#### Usando Python

```python
import requests

# Predicci√≥n individual
response = requests.post(
    "http://localhost:5000/predict",
    json={"store": 1, "item": 1, "date": "2018-01-15"}
)
print(response.json())

# Predicci√≥n batch
response = requests.post(
    "http://localhost:5000/predict/batch",
    json={
        "data": [
            {"store": 1, "item": 1, "date": "2018-01-15"},
            {"store": 2, "item": 3, "date": "2018-01-16"}
        ]
    }
)
print(response.json())
```

### Probar la API

```bash
# Ejecutar ejemplos de prueba
python tests/test_api_examples.py
```

---

## üöÄ Inicio R√°pido

```bash
# 1. Clonar el repositorio
git clone https://github.com/franciscogonzalez-gal/product_development.git
cd product_development

# 2. Crear entorno e instalar dependencias
conda env create -f environment.yml
conda activate product_development
pip install -e .

# 3. Ejecutar el pipeline DVC
dvc repro

# 4. Ver m√©tricas
dvc metrics show

# 5. Iniciar la API
python scripts/run_api.py
```

---

## üöÄ Instalaci√≥n

### Prerrequisitos
- Python 3.11
- Conda (recomendado) o pip

### Opci√≥n 1: Usando Conda (Recomendado)

```bash
# Clonar el repositorio
git clone https://github.com/franciscogonzalez-gal/product_development.git
cd product_development

# Crear entorno conda desde environment.yml
conda env create -f environment.yml

# Activar entorno
conda activate product_development

# Instalar el paquete en modo desarrollo
pip install -e .
```

### Opci√≥n 2: Usando pip

```bash
# Clonar el repositorio
git clone https://github.com/franciscogonzalez-gal/product_development.git
cd product_development

# Crear entorno virtual
python -m venv venv
source venv/bin/activate  # En Windows: venv\Scripts\activate

# Instalar el paquete en modo desarrollo
pip install -e .
```

---

## üíª Uso

### Ejecutar el Pipeline Completo

```bash
# Ejecutar pipeline completo (entrenamiento + inferencia)
python scripts/run_pipeline.py

# Solo inferencia (usando modelo existente)
python scripts/run_pipeline.py --skip-training

# Especificar rutas personalizadas
python scripts/run_pipeline.py \
    --input-path data/raw/train.csv \
    --output-path data/processed/predictions.csv
```

### Opciones del Pipeline

| Opci√≥n | Descripci√≥n |
|--------|-------------|
| `--input-path`, `-i` | Ruta a los datos crudos de entrenamiento |
| `--output-path`, `-o` | Ruta para guardar las predicciones |
| `--skip-training`, `-s` | Omitir entrenamiento y usar pipeline existente |
| `--inference-data`, `-d` | Ruta a datos para inferencia |

### Usar como Biblioteca

```python
from product_development.dataset import load_raw_data, prepare_dataset
from product_development.features import build_feature_pipeline
from product_development.modeling.train import train_and_evaluate_models
from product_development.modeling.predict import load_and_predict

# Cargar y preparar datos
data = load_raw_data()
prepared_data = prepare_dataset(data)

# Generar predicciones con modelo existente
predictions = load_and_predict(prepared_data)
```

---

## üìä MLflow - Tracking de Experimentos

El proyecto utiliza **MLflow** para el seguimiento de experimentos y registro de modelos.

### Configuraci√≥n de MLflow

```python
# En config.py
MLFLOW_TRACKING_URI = "mlruns"           # URI del servidor de tracking
MLFLOW_EXPERIMENT_NAME = "sales_prediction"
MLFLOW_MODEL_NAME = "sales_prediction_model"
MLFLOW_CHAMPION_ALIAS = "champion"       # Alias del modelo en producci√≥n
```

### Ver Experimentos

```bash
# Iniciar la UI de MLflow
mlflow ui --backend-store-uri mlruns

# Abrir en el navegador: http://localhost:5000
```

### Caracter√≠sticas de MLflow en el Proyecto

- üìà **Tracking de m√©tricas**: RMSE, MAE, R¬≤, MSE
- üîß **Registro de hiperpar√°metros**: Par√°metros del modelo
- üì¶ **Model Registry**: Gesti√≥n de versiones de modelos
- üè∑Ô∏è **Aliases**: Champion/Challenger para promoci√≥n de modelos

---

## üõ†Ô∏è Tecnolog√≠as Utilizadas

| Categor√≠a | Tecnolog√≠as |
|-----------|-------------|
| **Lenguaje** | Python 3.11 |
| **Manipulaci√≥n de Datos** | Pandas, NumPy |
| **Machine Learning** | Scikit-learn, XGBoost |
| **Ingenier√≠a de Caracter√≠sticas** | Feature-engine |
| **Visualizaci√≥n** | Matplotlib, Seaborn |
| **An√°lisis Estad√≠stico** | Statsmodels |
| **API REST** | Flask |
| **MLOps** | MLflow, DVC |
| **CLI** | Typer |
| **Logging** | Loguru |
| **Serializaci√≥n** | Joblib |
| **Configuraci√≥n** | python-dotenv, PyYAML |

---

## üìä Estructura de Datos

### Dataset de Entrada (`train.csv`)

| Columna | Tipo | Descripci√≥n |
|---------|------|-------------|
| `date` | datetime | Fecha de la venta |
| `store` | int | Identificador de la tienda |
| `item` | int | Identificador del art√≠culo |
| `sales` | int | Cantidad de ventas |

### Caracter√≠sticas Generadas

| Caracter√≠stica | Descripci√≥n |
|----------------|-------------|
| `year` | A√±o extra√≠do de la fecha |
| `month` | Mes extra√≠do de la fecha |
| `day_of_week_name` | Nombre del d√≠a de la semana |
| `store` (encoded) | Tienda codificada por frecuencia |
| `item` (encoded) | Art√≠culo codificado por frecuencia |

---

## üß™ Pruebas

```bash
# Ejecutar todas las pruebas
pytest tests/

# Ejecutar con cobertura
pytest tests/ --cov=product_development

# Ejecutar pruebas de datos
pytest tests/test_data.py

# Probar ejemplos de la API (requiere que la API est√© corriendo)
python tests/test_api_examples.py
```

---

## üõ†Ô∏è Comandos Makefile

El proyecto incluye un `Makefile` con comandos √∫tiles:

```bash
# Ver todos los comandos disponibles
make help

# Instalar dependencias
make requirements

# Ejecutar pipeline completo
make pipeline

# Solo inferencia (usando modelo existente)
make inference

# Entrenar modelo
make train

# Ejecutar pruebas
make test

# Formatear c√≥digo
make format

# Linting
make lint

# Ejecutar pylint
make pylint

# Limpiar archivos compilados
make clean

# Crear entorno conda
make create_environment
```

---

## üìà M√©tricas de Evaluaci√≥n

El modelo se eval√∫a utilizando:
- **RMSE** (Root Mean Square Error): M√©trica principal de evaluaci√≥n
- **MAE** (Mean Absolute Error): Error absoluto promedio
- **R¬≤** (Coeficiente de determinaci√≥n): Varianza explicada
- **MSE** (Mean Square Error): Error cuadr√°tico medio

### Modelos Evaluados

El pipeline eval√∫a autom√°ticamente los siguientes modelos:
- Regresi√≥n Lineal
- Random Forest
- Gradient Boosting
- XGBoost

El mejor modelo se selecciona autom√°ticamente bas√°ndose en RMSE y se registra en MLflow.

---

## üë• Autores

- **Francisco Gonz√°lez** - [franciscogonzalez-gal](https://github.com/franciscogonzalez-gal) - Universidad Galileo

---

## üìÑ Licencia

Este proyecto est√° bajo la Licencia MIT - ver el archivo [LICENSE](LICENSE) para m√°s detalles.

---

## üôè Agradecimientos

- [Cookiecutter Data Science](https://cookiecutter-data-science.drivendata.org/) por la plantilla del proyecto
- Universidad Galileo por el soporte acad√©mico

---

<p align="center">
  <i>Desarrollado con ‚ù§Ô∏è para el curso de Desarrollo de Producto</i>
</p>