# Product Development - PredicciÃ³n de Ventas

<a target="_blank" href="https://cookiecutter-data-science.drivendata.org/">
    <img src="https://img.shields.io/badge/CCDS-Project%20template-328F97?logo=cookiecutter" />
</a>

[![Python 3.11](https://img.shields.io/badge/python-3.11-blue.svg)](https://www.python.org/downloads/release/python-3110/)
[![License: CC BY 4.0](https://img.shields.io/badge/License-CC%20BY%204.0-lightgrey.svg)](https://creativecommons.org/licenses/by/4.0/)
[![DVC](https://img.shields.io/badge/DVC-Pipeline-945DD6?logo=dvc)](https://dvc.org/)
[![MLflow](https://img.shields.io/badge/MLflow-Tracking-0194E2?logo=mlflow)](https://mlflow.org/)
[![Flask](https://img.shields.io/badge/Flask-API-000000?logo=flask)](https://flask.palletsprojects.com/)

**Proyecto del Curso - Pipeline de MLOps para PredicciÃ³n de Ventas**

---

## ğŸ“‹ DescripciÃ³n

Este proyecto implementa un **pipeline completo de MLOps** para la predicciÃ³n de ventas utilizando tÃ©cnicas de machine learning. El sistema estÃ¡ diseÃ±ado siguiendo las mejores prÃ¡cticas de ciencia de datos e ingenierÃ­a de software, incluyendo:

- âœ… AnÃ¡lisis exploratorio de datos (EDA)
- âœ… IngenierÃ­a de caracterÃ­sticas automatizada
- âœ… Entrenamiento y selecciÃ³n de modelos
- âœ… Pipeline de inferencia reproducible
- âœ… Arquitectura modular y escalable
- âœ… **API REST** para predicciones en tiempo real
- âœ… **MLflow** para tracking de experimentos y model registry
- âœ… **DVC** para versionado de datos y pipelines reproducibles

---

## ğŸ¯ Objetivo del Proyecto

Desarrollar un sistema de predicciÃ³n de ventas que permita:
1. Procesar datos histÃ³ricos de ventas por tienda y artÃ­culo
2. Generar caracterÃ­sticas predictivas automÃ¡ticamente
3. Entrenar y evaluar mÃºltiples modelos de machine learning
4. Producir predicciones confiables para la planificaciÃ³n de inventario

---

## ğŸ“ OrganizaciÃ³n del Proyecto

```
product_development/
â”‚
â”œâ”€â”€ ğŸ“„ LICENSE                 <- Licencia de cÃ³digo abierto (CC BY 4.0)
â”œâ”€â”€ ğŸ“„ Makefile                <- Comandos Ãºtiles (make data, make train, etc.)
â”œâ”€â”€ ğŸ“„ README.md               <- DocumentaciÃ³n principal del proyecto
â”œâ”€â”€ ğŸ“„ pyproject.toml          <- ConfiguraciÃ³n del proyecto y dependencias
â”œâ”€â”€ ğŸ“„ environment.yml         <- Entorno conda con todas las dependencias
â”œâ”€â”€ ğŸ“„ dvc.yaml                <- DefiniciÃ³n del pipeline DVC
â”œâ”€â”€ ğŸ“„ params.yaml             <- ParÃ¡metros configurables del pipeline
â”‚
â”œâ”€â”€ ğŸ“‚ data/                   <- Datos del proyecto
â”‚   â”œâ”€â”€ external/              <- Datos de fuentes externas
â”‚   â”œâ”€â”€ processed/             <- Datos procesados listos para modelado
â”‚   â”‚   â”œâ”€â”€ prepared_data.csv  <- Dataset con caracterÃ­sticas temporales
â”‚   â”‚   â”œâ”€â”€ preproc_train.csv  <- Dataset preprocesado
â”‚   â”‚   â””â”€â”€ test_predictions.csv <- Predicciones generadas
â”‚   â””â”€â”€ raw/                   <- Datos originales (inmutables)
â”‚       â””â”€â”€ train.csv          <- Dataset de entrenamiento (date, store, item, sales)
â”‚
â”œâ”€â”€ ğŸ“‚ docs/                   <- DocumentaciÃ³n adicional del proyecto
â”‚   â”œâ”€â”€ API_DOCUMENTATION.md   <- ğŸ“– DocumentaciÃ³n completa de la API REST
â”‚   â””â”€â”€ DVC_PIPELINE.md        <- DocumentaciÃ³n del pipeline DVC
â”‚
â”œâ”€â”€ ğŸ“‚ models/                 <- Modelos entrenados serializados
â”‚   â”œâ”€â”€ feature_engineering_pipeline.pkl  <- Pipeline de ingenierÃ­a de caracterÃ­sticas
â”‚   â””â”€â”€ sales_pipeline.pkl                <- Pipeline completo de predicciÃ³n
â”‚
â”œâ”€â”€ ğŸ“‚ mlruns/                 <- Directorio de MLflow para tracking
â”‚   â””â”€â”€ ...                    <- Experimentos, mÃ©tricas y artefactos
â”‚
â”œâ”€â”€ ğŸ“‚ notebooks/              <- Jupyter notebooks del flujo de trabajo
â”‚   â”œâ”€â”€ 01_Data_Exploration.ipynb      <- EDA: anÃ¡lisis y visualizaciones
â”‚   â”œâ”€â”€ 02_feature_exploration.ipynb   <- ExploraciÃ³n de caracterÃ­sticas
â”‚   â”œâ”€â”€ 03_feature_creation.ipynb      <- CreaciÃ³n de features con sklearn
â”‚   â”œâ”€â”€ 04_model_tuning_training.ipynb <- Ajuste y entrenamiento de modelos
â”‚   â”œâ”€â”€ 05_inference_calculation.ipynb <- CÃ¡lculo de predicciones
â”‚   â””â”€â”€ operators.py                   <- Transformadores para notebooks
â”‚
â”œâ”€â”€ ğŸ“‚ references/             <- Diccionarios de datos y materiales de referencia
â”‚
â”œâ”€â”€ ğŸ“‚ reports/                <- Reportes y anÃ¡lisis generados
â”‚   â”œâ”€â”€ metrics.json           <- MÃ©tricas del modelo (generado por DVC)
â”‚   â””â”€â”€ figures/               <- GrÃ¡ficos y figuras para reportes
â”‚
â”œâ”€â”€ ğŸ“‚ tests/                  <- Pruebas unitarias
â”‚   â”œâ”€â”€ test_data.py           <- Tests de validaciÃ³n de datos
â”‚   â””â”€â”€ test_api_examples.py   <- Ejemplos de consumo de la API
â”‚
â”œâ”€â”€ ğŸ“‚ scripts/                <- Scripts auxiliares
â”‚   â”œâ”€â”€ dvc_train.py           <- Script de entrenamiento para DVC
â”‚   â”œâ”€â”€ dvc_inference.py       <- Script de inferencia para DVC
â”‚   â”œâ”€â”€ run_api.py             <- Script para ejecutar la API
â”‚   â””â”€â”€ run_pipeline.py        <- Script principal del pipeline MLOps
â”‚
â””â”€â”€ ğŸ“‚ product_development/    <- ğŸ“¦ CÃ³digo fuente del paquete
    â”‚
    â”œâ”€â”€ __init__.py            <- InicializaciÃ³n del mÃ³dulo Python
    â”œâ”€â”€ config.py              <- ConfiguraciÃ³n de rutas y constantes
    â”œâ”€â”€ dataset.py             <- Funciones de carga y preparaciÃ³n de datos
    â”œâ”€â”€ features.py            <- Pipeline de ingenierÃ­a de caracterÃ­sticas
    â”œâ”€â”€ plots.py               <- Funciones de visualizaciÃ³n
    â”œâ”€â”€ transformers.py        <- Transformadores personalizados de sklearn
    â”œâ”€â”€ api.py                 <- ğŸŒ API REST Flask para predicciones
    â”‚
    â””â”€â”€ modeling/              <- SubmÃ³dulo de modelado
        â”œâ”€â”€ __init__.py
        â”œâ”€â”€ train.py           <- Entrenamiento y evaluaciÃ³n de modelos
        â””â”€â”€ predict.py         <- Inferencia y generaciÃ³n de predicciones
```

---

## ğŸ”„ Flujo de Trabajo

El proyecto sigue un flujo de trabajo estructurado en 5 etapas:

### 1ï¸âƒ£ ExploraciÃ³n de Datos
**Notebook:** `01_Data_Exploration.ipynb`

- AnÃ¡lisis exploratorio del dataset de ventas
- EstadÃ­sticas descriptivas por tienda y artÃ­culo
- Visualizaciones de series temporales
- IdentificaciÃ³n de patrones y tendencias

### 2ï¸âƒ£ ExploraciÃ³n de CaracterÃ­sticas
**Notebook:** `02_feature_exploration.ipynb`

- AnÃ¡lisis de correlaciones
- EvaluaciÃ³n de variables candidatas
- SelecciÃ³n de caracterÃ­sticas relevantes

### 3ï¸âƒ£ CreaciÃ³n de CaracterÃ­sticas
**Notebook:** `03_feature_creation.ipynb`

Pipeline de ingenierÃ­a de caracterÃ­sticas que incluye:
- ğŸ“Š **Features de Lag**: 1, 7, 14, 28 dÃ­as
- ğŸ“ˆ **Medias MÃ³viles**: ventanas de 7 y 28 dÃ­as
- ğŸ·ï¸ **CodificaciÃ³n de Frecuencia**: para tiendas e items
- ğŸ“… **Features Temporales**: aÃ±o, mes, dÃ­a de la semana
- âš–ï¸ **Escalado MinMax**: normalizaciÃ³n de caracterÃ­sticas

### 4ï¸âƒ£ Entrenamiento del Modelo
**Notebook:** `04_model_tuning_training.ipynb`

EvaluaciÃ³n de mÃºltiples algoritmos:
- RegresiÃ³n Lineal
- Random Forest
- Gradient Boosting
- Support Vector Regression (SVR)
- XGBoost

### 5ï¸âƒ£ Inferencia
**Notebook:** `05_inference_calculation.ipynb`

- Carga del pipeline entrenado
- GeneraciÃ³n de predicciones
- EvaluaciÃ³n de mÃ©tricas (RMSE)

---

## ğŸ”„ Pipeline DVC

El proyecto incluye un **pipeline DVC** para automatizar y reproducir el flujo de trabajo completo.

### Estructura del Pipeline

```
prepare_data â†’ feature_engineering â†’ train_model â†’ inference
```

| Etapa | Entrada | Salida | DescripciÃ³n |
|-------|---------|--------|-------------|
| `prepare_data` | `data/raw/train.csv` | `data/processed/prepared_data.csv` | Carga datos y agrega features temporales |
| `feature_engineering` | `prepared_data.csv` | `feature_engineering_pipeline.pkl` | Construye pipeline de caracterÃ­sticas |
| `train_model` | `prepared_data.csv`, `pipeline.pkl` | `sales_pipeline.pkl`, `metrics.json` | Entrena y evalÃºa modelos |
| `inference` | `prepared_data.csv`, `sales_pipeline.pkl` | `test_predictions.csv` | Genera predicciones |

### Comandos DVC

```bash
# Ejecutar todo el pipeline
dvc repro

# Ejecutar una etapa especÃ­fica
dvc repro train_model

# Ver estado del pipeline
dvc status

# Ver grafo de dependencias
dvc dag

# Ver mÃ©tricas
dvc metrics show

# Comparar mÃ©tricas entre experimentos
dvc metrics diff
```

### ParÃ¡metros del Pipeline (`params.yaml`)

```yaml
# ConfiguraciÃ³n de divisiÃ³n de datos
data:
  train_test_split_ratio: 0.8    # ProporciÃ³n train/test
  random_state: 2025             # Semilla para reproducibilidad

# ConfiguraciÃ³n de caracterÃ­sticas
features:
  target: "sales"
  feature_columns:
    - "store"
    - "item"
    - "year"
    - "month"
    - "day_of_week_name"
  categorical_vars:
    - "store"
    - "item"
    - "day_of_week_name"
  numerical_vars:
    - "year"
    - "month"

# ConfiguraciÃ³n de entrenamiento
training:
  mode: "fast"                   # "fast" o "full"
  use_mlflow: true               # Registrar en MLflow

# ConfiguraciÃ³n de MLflow
mlflow:
  tracking_uri: "mlruns"
  experiment_name: "sales_prediction"
  model_name: "sales_prediction_model"
```

> ğŸ“– Para mÃ¡s detalles, consulta [docs/DVC_PIPELINE.md](docs/DVC_PIPELINE.md)

---

## ğŸŒ API REST

El proyecto incluye una **API REST** construida con Flask para realizar predicciones en tiempo real.

> ğŸ“– **DocumentaciÃ³n completa de la API:** [docs/API_DOCUMENTATION.md](docs/API_DOCUMENTATION.md)

### Iniciar la API

```bash
# OpciÃ³n 1: Usando el script de scripts/
python scripts/run_api.py

# OpciÃ³n 2: Con opciones personalizadas
python scripts/run_api.py --host 0.0.0.0 --port 5000 --debug

# OpciÃ³n 3: Ejecutando directamente el mÃ³dulo api
python -m product_development.api
```

### Endpoints Disponibles

| Endpoint | MÃ©todo | DescripciÃ³n |
|----------|--------|-------------|
| `/` | GET | InformaciÃ³n de la API |
| `/health` | GET | Health check del servicio |
| `/model/info` | GET | InformaciÃ³n del modelo (mÃ©tricas, hiperparÃ¡metros) |
| `/predict` | POST | PredicciÃ³n individual |
| `/predict/batch` | POST | PredicciÃ³n por lote |

### Ejemplos de Uso

#### PredicciÃ³n Individual

```bash
curl -X POST http://localhost:5000/predict \
  -H "Content-Type: application/json" \
  -d '{"store": 1, "item": 1, "date": "2018-01-15"}'
```

**Respuesta:**
```json
{
  "predictions": [42.35],
  "model_metrics": {"rmse": 13.08, "mae": 10.25, "r2": 0.91},
  "timestamp": "2024-01-15T10:30:00",
  "prediction_count": 1
}
```

#### PredicciÃ³n por Lote (Batch)

```bash
curl -X POST http://localhost:5000/predict/batch \
  -H "Content-Type: application/json" \
  -d '{
    "data": [
      {"store": 1, "item": 1, "date": "2018-01-15"},
      {"store": 2, "item": 3, "date": "2018-01-16"},
      {"store": 5, "item": 10, "date": "2018-02-01"}
    ]
  }'
```

#### Usando Python

```python
import requests

# PredicciÃ³n individual
response = requests.post(
    "http://localhost:5000/predict",
    json={"store": 1, "item": 1, "date": "2018-01-15"}
)
print(response.json())

# PredicciÃ³n batch
response = requests.post(
    "http://localhost:5000/predict/batch",
    json={
        "data": [
            {"store": 1, "item": 1, "date": "2018-01-15"},
            {"store": 2, "item": 3, "date": "2018-01-16"}
        ]
    }
)
print(response.json())
```

### Probar la API

```bash
# Ejecutar ejemplos de prueba
python tests/test_api_examples.py
```

---

## ğŸš€ Inicio RÃ¡pido

```bash
# 1. Clonar el repositorio
git clone https://github.com/franciscogonzalez-gal/product_development.git
cd product_development

# 2. Crear entorno e instalar dependencias
conda env create -f environment.yml
conda activate product_development
pip install -e .

# 3. Ejecutar el pipeline DVC
dvc repro

# 4. Ver mÃ©tricas
dvc metrics show

# 5. Iniciar la API
python scripts/run_api.py
```

---

## ğŸš€ InstalaciÃ³n

### Prerrequisitos
- Python 3.11
- Conda (recomendado) o pip

### OpciÃ³n 1: Usando Conda (Recomendado)

```bash
# Clonar el repositorio
git clone https://github.com/franciscogonzalez-gal/product_development.git
cd product_development

# Crear entorno conda desde environment.yml
conda env create -f environment.yml

# Activar entorno
conda activate product_development

# Instalar el paquete en modo desarrollo
pip install -e .
```

### OpciÃ³n 2: Usando pip

```bash
# Clonar el repositorio
git clone https://github.com/franciscogonzalez-gal/product_development.git
cd product_development

# Crear entorno virtual
python -m venv venv
source venv/bin/activate  # En Windows: venv\Scripts\activate

# Instalar el paquete en modo desarrollo
pip install -e .
```

---

## ğŸ’» Uso

### Ejecutar el Pipeline Completo

```bash
# Ejecutar pipeline completo (entrenamiento + inferencia)
python scripts/run_pipeline.py

# Solo inferencia (usando modelo existente)
python scripts/run_pipeline.py --skip-training

# Especificar rutas personalizadas
python scripts/run_pipeline.py \
    --input-path data/raw/train.csv \
    --output-path data/processed/predictions.csv
```

### Opciones del Pipeline

| OpciÃ³n | DescripciÃ³n |
|--------|-------------|
| `--input-path`, `-i` | Ruta a los datos crudos de entrenamiento |
| `--output-path`, `-o` | Ruta para guardar las predicciones |
| `--skip-training`, `-s` | Omitir entrenamiento y usar pipeline existente |
| `--inference-data`, `-d` | Ruta a datos para inferencia |

### Usar como Biblioteca

```python
from product_development.dataset import load_raw_data, prepare_dataset
from product_development.features import build_feature_pipeline
from product_development.modeling.train import train_and_evaluate_models
from product_development.modeling.predict import load_and_predict

# Cargar y preparar datos
data = load_raw_data()
prepared_data = prepare_dataset(data)

# Generar predicciones con modelo existente
predictions = load_and_predict(prepared_data)
```

---

## ğŸ“Š MLflow - Tracking de Experimentos

El proyecto utiliza **MLflow** para el seguimiento de experimentos y registro de modelos.

### Dashboard de Experimentos

![MLflow Experiments Dashboard](reports/figures/mlflow_experiments.png)

*Interfaz de MLflow mostrando los experimentos de entrenamiento con diferentes modelos (XGBoost, GradientBoosting, RandomForest, LinearRegression).*

### ConfiguraciÃ³n de MLflow

```python
# En config.py
MLFLOW_TRACKING_URI = "mlruns"           # URI del servidor de tracking
MLFLOW_EXPERIMENT_NAME = "sales_prediction"
MLFLOW_MODEL_NAME = "sales_prediction_model"
MLFLOW_CHAMPION_ALIAS = "champion"       # Alias del modelo en producciÃ³n
```

### Ver Experimentos

```bash
# Iniciar la UI de MLflow
mlflow ui --backend-store-uri mlruns

# Abrir en el navegador: http://localhost:5000

# Si en Windows aparece error de multiprocessing, usar un solo worker:
mlflow ui --backend-store-uri mlruns --workers 1
```

### CaracterÃ­sticas de MLflow en el Proyecto

- ğŸ“ˆ **Tracking de mÃ©tricas**: RMSE, MAE, RÂ², MSE
- ğŸ”§ **Registro de hiperparÃ¡metros**: ParÃ¡metros del modelo
- ğŸ“¦ **Model Registry**: GestiÃ³n de versiones de modelos
- ğŸ·ï¸ **Aliases**: Champion/Challenger para promociÃ³n de modelos

---

## ğŸ› ï¸ TecnologÃ­as Utilizadas

| CategorÃ­a | TecnologÃ­as |
|-----------|-------------|
| **Lenguaje** | Python 3.11 |
| **ManipulaciÃ³n de Datos** | Pandas, NumPy |
| **Machine Learning** | Scikit-learn, XGBoost |
| **IngenierÃ­a de CaracterÃ­sticas** | Feature-engine |
| **VisualizaciÃ³n** | Matplotlib, Seaborn |
| **AnÃ¡lisis EstadÃ­stico** | Statsmodels |
| **API REST** | Flask |
| **MLOps** | MLflow, DVC |
| **CLI** | Typer |
| **Logging** | Loguru |
| **SerializaciÃ³n** | Joblib |
| **ConfiguraciÃ³n** | python-dotenv, PyYAML |

---

## ğŸ“Š Estructura de Datos

### Dataset de Entrada (`train.csv`)

| Columna | Tipo | DescripciÃ³n |
|---------|------|-------------|
| `date` | datetime | Fecha de la venta |
| `store` | int | Identificador de la tienda |
| `item` | int | Identificador del artÃ­culo |
| `sales` | int | Cantidad de ventas |

### CaracterÃ­sticas Generadas

| CaracterÃ­stica | DescripciÃ³n |
|----------------|-------------|
| `year` | AÃ±o extraÃ­do de la fecha |
| `month` | Mes extraÃ­do de la fecha |
| `day_of_week_name` | Nombre del dÃ­a de la semana |
| `store` (encoded) | Tienda codificada por frecuencia |
| `item` (encoded) | ArtÃ­culo codificado por frecuencia |

---

## ğŸ§ª Pruebas

```bash
# Ejecutar todas las pruebas
pytest tests/

# Ejecutar con cobertura
pytest tests/ --cov=product_development

# Ejecutar pruebas de datos
pytest tests/test_data.py

# Probar ejemplos de la API (requiere que la API estÃ© corriendo)
python tests/test_api_examples.py
```

---

## ğŸ” AnÃ¡lisis de CÃ³digo - Pylint

El proyecto ha sido analizado con **Pylint** para asegurar la calidad del cÃ³digo.

### PuntuaciÃ³n Actual

```
ğŸ“Š Your code has been rated at 9.10/10
```

### Resumen de Advertencias

La mayorÃ­a de las advertencias son convenciones de nomenclatura (C0103) relacionadas con variables como `X`, `X_train`, `X_test`, que siguen la convenciÃ³n estÃ¡ndar de machine learning para representar matrices de caracterÃ­sticas.

| Tipo | CÃ³digo | DescripciÃ³n | Cantidad |
|------|--------|-------------|----------|
| Convention | C0103 | Variables que no siguen snake_case (`X`, `X_train`, etc.) | 26 |
| Convention | C0104 | Nombre no permitido (`bar` en plots.py) | 1 |
| Warning | W0611 | Imports no utilizados | 5 |
| Warning | W0612 | Variables no utilizadas | 3 |
| Warning | W0613 | Argumentos no utilizados | 3 |
| Refactor | R0917 | Demasiados argumentos posicionales | 1 |

### Detalle por MÃ³dulo

| MÃ³dulo | Advertencias |
|--------|--------------|
| `product_development.dataset` | 3 (naming conventions) |
| `product_development.features` | 4 (naming conventions) |
| `product_development.plots` | 1 (disallowed name) |
| `product_development.run_pipeline` | 16 (naming, unused imports/vars) |
| `product_development.transformers` | 4 (naming conventions) |
| `product_development.modeling.predict` | 3 (naming conventions) |
| `product_development.modeling.train` | 5 (naming, unused args/vars) |

### Ejecutar Pylint

```bash
# Ejecutar anÃ¡lisis de pylint
make pylint

# O directamente
pylint product_development/ --output-format=text > pylint_report.txt
```

> **Nota:** Las convenciones de nomenclatura con `X` y `X_train` son intencionales y siguen el estÃ¡ndar de scikit-learn para matrices de caracterÃ­sticas.

---

## ğŸ› ï¸ Comandos Makefile

El proyecto incluye un `Makefile` con comandos Ãºtiles:

```bash
# Ver todos los comandos disponibles
make help

# Instalar dependencias
make requirements

# Ejecutar pipeline completo
make pipeline

# Solo inferencia (usando modelo existente)
make inference

# Entrenar modelo
make train

# Ejecutar pruebas
make test

# Formatear cÃ³digo
make format

# Linting
make lint

# Ejecutar pylint
make pylint

# Limpiar archivos compilados
make clean

# Crear entorno conda
make create_environment
```

---

## ğŸ“ˆ MÃ©tricas de EvaluaciÃ³n

El modelo se evalÃºa utilizando:
- **RMSE** (Root Mean Square Error): MÃ©trica principal de evaluaciÃ³n
- **MAE** (Mean Absolute Error): Error absoluto promedio
- **RÂ²** (Coeficiente de determinaciÃ³n): Varianza explicada
- **MSE** (Mean Square Error): Error cuadrÃ¡tico medio

### Modelos Evaluados

El pipeline evalÃºa automÃ¡ticamente los siguientes modelos:
- RegresiÃ³n Lineal
- Random Forest
- Gradient Boosting
- XGBoost

El mejor modelo se selecciona automÃ¡ticamente basÃ¡ndose en RMSE y se registra en MLflow.

---

## ğŸ‘¥ Autores

- **Francisco GonzÃ¡lez** - [GitHub](https://github.com/franciscogonzalez-gal) | [LinkedIn](https://www.linkedin.com/in/franciscogonzalez/) - Universidad Galileo
- **Natalie Medina** - [LinkedIn](https://www.linkedin.com/in/natalie-medina-/) - Universidad Galileo
- **Karl Van Tuylen** - [LinkedIn](https://www.linkedin.com/in/karl-van-tuylen-mota-3b10662a4/) - Universidad Galileo
- **Vincent MartÃ­nez** - [LinkedIn](https://www.linkedin.com/in/vincentmart%C3%ADnez/) - Universidad Galileo

---

## ğŸ“„ Licencia

Este proyecto estÃ¡ bajo la Licencia Creative Commons Attribution 4.0 International (CC BY 4.0) - ver el archivo [LICENSE](LICENSE) para mÃ¡s detalles.

---

## ğŸ™ Agradecimientos

- [Cookiecutter Data Science](https://cookiecutter-data-science.drivendata.org/) por la plantilla del proyecto
- Universidad Galileo por el soporte acadÃ©mico

---

<p align="center">
  <i>Desarrollado con â¤ï¸ para el curso de Desarrollo de Producto</i>
</p>