{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "417a4b12",
   "metadata": {},
   "source": [
    "# 1 Cargamos librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "15fe8baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importaciones\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import joblib\n",
    "import mlflow\n",
    "from mlflow.tracking import MlflowClient\n",
    "\n",
    "from loguru import logger\n",
    "\n",
    "# Importar m√≥dulos del paquete product_development\n",
    "from product_development.config import (\n",
    "    TARGET, FEATURES, CATEGORICAL_VARS, RAW_DATA_DIR, MODELS_DIR,\n",
    "    FEATURE_PIPELINE_FILE, PIPELINE_FILE, TRAIN_TEST_SPLIT_RATIO, RANDOM_STATE,\n",
    "    MLFLOW_EXPERIMENT_NAME, MLFLOW_MODEL_NAME, MLFLOW_TRACKING_URI,\n",
    "    MLFLOW_CHAMPION_ALIAS, MLFLOW_CHALLENGER_ALIAS\n",
    ")\n",
    "from product_development.dataset import load_raw_data, prepare_dataset, temporal_train_test_split\n",
    "from product_development.features import load_feature_pipeline, transform_features\n",
    "from product_development.modeling.train import (\n",
    "    get_model_configurations, train_and_evaluate_models,\n",
    "    create_full_pipeline, train_final_model, save_pipeline,\n",
    "    setup_mlflow, register_model_to_mlflow, get_champion_model,\n",
    "    compare_with_champion, promote_challenger_to_champion, get_experiment_summary,\n",
    "    calculate_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67cd25ba",
   "metadata": {},
   "source": [
    "Configuraci√≥n de modelos, logging y rutas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0d14a3a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-11-29 10:24:07.206\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mproduct_development.modeling.train\u001b[0m:\u001b[36msetup_mlflow\u001b[0m:\u001b[36m155\u001b[0m - \u001b[1mMLflow configurado - Experimento: sales_prediction\u001b[0m\n",
      "MLflow Experiment ID: 781360344278088554\n",
      "MLflow Tracking URI: mlruns\n",
      "\n",
      "Modo de entrenamiento: fast\n",
      "Total de modelos a evaluar: 4\n",
      "\n",
      "Modelos configurados:\n",
      "  - LinearRegression\n",
      "  - RandomForest\n",
      "  - GradientBoosting\n",
      "  - XGBoost\n"
     ]
    }
   ],
   "source": [
    "# 2. Configuraci√≥n de modelos y MLflow\n",
    "# Modo: \"fast\" (r√°pido, 4 modelos) o \"full\" (completo, 15 modelos)\n",
    "TRAINING_MODE = \"fast\"  # Cambiar a \"full\" para evaluaci√≥n completa\n",
    "USE_MLFLOW = True  # Habilitar/deshabilitar tracking de MLflow\n",
    "\n",
    "# Configurar MLflow\n",
    "if USE_MLFLOW:\n",
    "    experiment_id = setup_mlflow(MLFLOW_EXPERIMENT_NAME, MLFLOW_TRACKING_URI)\n",
    "    print(f\"MLflow Experiment ID: {experiment_id}\")\n",
    "    print(f\"MLflow Tracking URI: {MLFLOW_TRACKING_URI}\")\n",
    "\n",
    "models_configurations = get_model_configurations(mode=TRAINING_MODE)\n",
    "\n",
    "print(f\"\\nModo de entrenamiento: {TRAINING_MODE}\")\n",
    "print(f\"Total de modelos a evaluar: {len(models_configurations)}\")\n",
    "print(\"\\nModelos configurados:\")\n",
    "for name in models_configurations.keys():\n",
    "    print(f\"  - {name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5dde955",
   "metadata": {},
   "source": [
    "# 3 Entrenamiento y seleccion de modelos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2354bb3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-11-29 10:24:07.217\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mproduct_development.dataset\u001b[0m:\u001b[36mload_raw_data\u001b[0m:\u001b[36m49\u001b[0m - \u001b[1mCargando datos crudos desde C:\\Users\\fjgon\\OneDrive - Universidad Galileo\\Trimestre 8\\product_development\\data\\raw\\train.csv\u001b[0m\n",
      "\u001b[32m2025-11-29 10:24:07.533\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mproduct_development.dataset\u001b[0m:\u001b[36mload_raw_data\u001b[0m:\u001b[36m51\u001b[0m - \u001b[1mCargados 913000 registros\u001b[0m\n",
      "\u001b[32m2025-11-29 10:24:07.534\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mproduct_development.dataset\u001b[0m:\u001b[36madd_temporal_features\u001b[0m:\u001b[36m69\u001b[0m - \u001b[1mAgregando caracter√≠sticas temporales\u001b[0m\n",
      "\u001b[32m2025-11-29 10:24:07.669\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mproduct_development.dataset\u001b[0m:\u001b[36mconvert_categorical_types\u001b[0m:\u001b[36m92\u001b[0m - \u001b[1mConvirtiendo columnas categ√≥ricas a tipo object\u001b[0m\n",
      "Total registros: 913000\n",
      "\u001b[32m2025-11-29 10:24:07.731\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mproduct_development.dataset\u001b[0m:\u001b[36mtemporal_train_test_split\u001b[0m:\u001b[36m140\u001b[0m - \u001b[1mDividiendo datos con 80% para entrenamiento\u001b[0m\n",
      "\u001b[32m2025-11-29 10:24:07.533\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mproduct_development.dataset\u001b[0m:\u001b[36mload_raw_data\u001b[0m:\u001b[36m51\u001b[0m - \u001b[1mCargados 913000 registros\u001b[0m\n",
      "\u001b[32m2025-11-29 10:24:07.534\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mproduct_development.dataset\u001b[0m:\u001b[36madd_temporal_features\u001b[0m:\u001b[36m69\u001b[0m - \u001b[1mAgregando caracter√≠sticas temporales\u001b[0m\n",
      "\u001b[32m2025-11-29 10:24:07.669\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mproduct_development.dataset\u001b[0m:\u001b[36mconvert_categorical_types\u001b[0m:\u001b[36m92\u001b[0m - \u001b[1mConvirtiendo columnas categ√≥ricas a tipo object\u001b[0m\n",
      "Total registros: 913000\n",
      "\u001b[32m2025-11-29 10:24:07.731\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mproduct_development.dataset\u001b[0m:\u001b[36mtemporal_train_test_split\u001b[0m:\u001b[36m140\u001b[0m - \u001b[1mDividiendo datos con 80% para entrenamiento\u001b[0m\n",
      "\u001b[32m2025-11-29 10:24:07.932\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mproduct_development.dataset\u001b[0m:\u001b[36mtemporal_train_test_split\u001b[0m:\u001b[36m151\u001b[0m - \u001b[1mTama√±o entrenamiento: 730400, Tama√±o prueba: 182600\u001b[0m\n",
      "Train: (730400, 5), Val: (182600, 5)\n",
      "\u001b[32m2025-11-29 10:24:07.953\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mproduct_development.features\u001b[0m:\u001b[36mload_feature_pipeline\u001b[0m:\u001b[36m172\u001b[0m - \u001b[1mCargando pipeline de caracter√≠sticas desde C:\\Users\\fjgon\\OneDrive - Universidad Galileo\\Trimestre 8\\product_development\\models\\feature_engineering_pipeline.pkl\u001b[0m\n",
      "\u001b[32m2025-11-29 10:24:07.932\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mproduct_development.dataset\u001b[0m:\u001b[36mtemporal_train_test_split\u001b[0m:\u001b[36m151\u001b[0m - \u001b[1mTama√±o entrenamiento: 730400, Tama√±o prueba: 182600\u001b[0m\n",
      "Train: (730400, 5), Val: (182600, 5)\n",
      "\u001b[32m2025-11-29 10:24:07.953\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mproduct_development.features\u001b[0m:\u001b[36mload_feature_pipeline\u001b[0m:\u001b[36m172\u001b[0m - \u001b[1mCargando pipeline de caracter√≠sticas desde C:\\Users\\fjgon\\OneDrive - Universidad Galileo\\Trimestre 8\\product_development\\models\\feature_engineering_pipeline.pkl\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\fjgon\\OneDrive - Universidad Galileo\\Trimestre 8\\product_development\\notebooks\\..\\product_development\\transformers.py:135: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  X[var] = X[var].fillna(self.fill_value).astype(str)\n",
      "c:\\Users\\fjgon\\OneDrive - Universidad Galileo\\Trimestre 8\\product_development\\notebooks\\..\\product_development\\transformers.py:135: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  X[var] = X[var].fillna(self.fill_value).astype(str)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-11-29 10:24:09.006\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mproduct_development.features\u001b[0m:\u001b[36mtransform_features\u001b[0m:\u001b[36m126\u001b[0m - \u001b[1mTransformando 730400 registros\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\fjgon\\OneDrive - Universidad Galileo\\Trimestre 8\\product_development\\notebooks\\..\\product_development\\transformers.py:135: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  X[var] = X[var].fillna(self.fill_value).astype(str)\n",
      "c:\\Users\\fjgon\\OneDrive - Universidad Galileo\\Trimestre 8\\product_development\\notebooks\\..\\product_development\\transformers.py:135: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  X[var] = X[var].fillna(self.fill_value).astype(str)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-11-29 10:24:09.832\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mproduct_development.features\u001b[0m:\u001b[36mtransform_features\u001b[0m:\u001b[36m126\u001b[0m - \u001b[1mTransformando 182600 registros\u001b[0m\n",
      "Shape X_train_proc: (730400, 5)\n",
      "Shape X_val_proc: (182600, 5)\n",
      "Shape X_train_proc: (730400, 5)\n",
      "Shape X_val_proc: (182600, 5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\fjgon\\OneDrive - Universidad Galileo\\Trimestre 8\\product_development\\notebooks\\..\\product_development\\transformers.py:135: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  X[var] = X[var].fillna(self.fill_value).astype(str)\n",
      "c:\\Users\\fjgon\\OneDrive - Universidad Galileo\\Trimestre 8\\product_development\\notebooks\\..\\product_development\\transformers.py:135: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  X[var] = X[var].fillna(self.fill_value).astype(str)\n"
     ]
    }
   ],
   "source": [
    "# 3. Cargar y preparar datos usando los m√≥dulos del paquete\n",
    "raw_data = load_raw_data(RAW_DATA_DIR / \"train.csv\")\n",
    "dataset = prepare_dataset(raw_data)\n",
    "\n",
    "print(f\"Total registros: {len(dataset)}\")\n",
    "\n",
    "# Split temporal 80/20\n",
    "X_train, X_val, y_train, y_val = temporal_train_test_split(dataset, TRAIN_TEST_SPLIT_RATIO)\n",
    "\n",
    "print(f\"Train: {X_train.shape}, Val: {X_val.shape}\")\n",
    "\n",
    "# Cargar pipeline de preprocesamiento\n",
    "preproc_pipeline = load_feature_pipeline(FEATURE_PIPELINE_FILE)\n",
    "\n",
    "# Ajustar pipeline con datos de entrenamiento\n",
    "preproc_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Transformar datos\n",
    "X_train_proc = transform_features(preproc_pipeline, X_train)\n",
    "X_val_proc = transform_features(preproc_pipeline, X_val)\n",
    "\n",
    "print(f\"Shape X_train_proc: {X_train_proc.shape}\")\n",
    "print(f\"Shape X_val_proc: {X_val_proc.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "16a82774",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-11-29 10:24:10.044\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mproduct_development.modeling.train\u001b[0m:\u001b[36mtrain_and_evaluate_models\u001b[0m:\u001b[36m245\u001b[0m - \u001b[1mIniciando entrenamiento y evaluaci√≥n de modelos\u001b[0m\n",
      "\u001b[32m2025-11-29 10:24:10.052\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mproduct_development.modeling.train\u001b[0m:\u001b[36msetup_mlflow\u001b[0m:\u001b[36m155\u001b[0m - \u001b[1mMLflow configurado - Experimento: sales_prediction\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Entrenando modelos:   0%|          | 0/4 [00:00<?, ?it/s]2025/11/29 10:24:10 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/11/29 10:24:10 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-11-29 10:24:10.053\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mproduct_development.modeling.train\u001b[0m:\u001b[36mtrain_and_evaluate_models\u001b[0m:\u001b[36m252\u001b[0m - \u001b[1mEntrenando modelo: LinearRegression\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/29 10:24:13 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "Entrenando modelos:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:03<00:09,  3.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-11-29 10:24:13.362\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mproduct_development.modeling.train\u001b[0m:\u001b[36mtrain_and_evaluate_models\u001b[0m:\u001b[36m281\u001b[0m - \u001b[1mModelo LinearRegression - RMSE: 30.0452, R2: 0.0931\u001b[0m\n",
      "\u001b[32m2025-11-29 10:24:13.362\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mproduct_development.modeling.train\u001b[0m:\u001b[36mtrain_and_evaluate_models\u001b[0m:\u001b[36m252\u001b[0m - \u001b[1mEntrenando modelo: RandomForest\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/29 10:24:17 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/11/29 10:24:20 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/11/29 10:24:20 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "Entrenando modelos:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:10<00:11,  5.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-11-29 10:24:20.627\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mproduct_development.modeling.train\u001b[0m:\u001b[36mtrain_and_evaluate_models\u001b[0m:\u001b[36m281\u001b[0m - \u001b[1mModelo RandomForest - RMSE: 27.4841, R2: 0.2411\u001b[0m\n",
      "\u001b[32m2025-11-29 10:24:20.644\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mproduct_development.modeling.train\u001b[0m:\u001b[36mtrain_and_evaluate_models\u001b[0m:\u001b[36m252\u001b[0m - \u001b[1mEntrenando modelo: GradientBoosting\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/29 10:24:39 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/11/29 10:24:42 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/11/29 10:24:42 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "Entrenando modelos:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:32<00:13, 13.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-11-29 10:24:42.476\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mproduct_development.modeling.train\u001b[0m:\u001b[36mtrain_and_evaluate_models\u001b[0m:\u001b[36m281\u001b[0m - \u001b[1mModelo GradientBoosting - RMSE: 27.1293, R2: 0.2605\u001b[0m\n",
      "\u001b[32m2025-11-29 10:24:42.481\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mproduct_development.modeling.train\u001b[0m:\u001b[36mtrain_and_evaluate_models\u001b[0m:\u001b[36m252\u001b[0m - \u001b[1mEntrenando modelo: XGBoost\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/29 10:24:43 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/11/29 10:24:46 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/11/29 10:24:46 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "Entrenando modelos: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:36<00:00,  9.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-11-29 10:24:46.599\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mproduct_development.modeling.train\u001b[0m:\u001b[36mtrain_and_evaluate_models\u001b[0m:\u001b[36m281\u001b[0m - \u001b[1mModelo XGBoost - RMSE: 26.9235, R2: 0.2717\u001b[0m\n",
      "\u001b[32m2025-11-29 10:24:46.607\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mproduct_development.modeling.train\u001b[0m:\u001b[36mtrain_and_evaluate_models\u001b[0m:\u001b[36m301\u001b[0m - \u001b[1mMejor modelo: XGBoost con RMSE = 26.9235\u001b[0m\n",
      "\n",
      "Tiempo total de entrenamiento: 36.56 segundos\n",
      "\n",
      "Resultados de todos los modelos:\n",
      "  LinearRegression: RMSE=30.0452, R2=0.0931\n",
      "  RandomForest: RMSE=27.4841, R2=0.2411\n",
      "  GradientBoosting: RMSE=27.1293, R2=0.2605\n",
      "  XGBoost: RMSE=26.9235, R2=0.2717\n",
      "\n",
      "üèÜ Mejor modelo: XGBoost\n",
      "   RMSE: 26.9235\n",
      "   R2: 0.2717\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 4. Entrenamiento y evaluaci√≥n de modelos con MLflow tracking\n",
    "start = time.time()\n",
    "\n",
    "results, best_model_name, best_model = train_and_evaluate_models(\n",
    "    X_train_proc, y_train,\n",
    "    X_val_proc, y_val,\n",
    "    models_configurations,\n",
    "    use_mlflow=USE_MLFLOW\n",
    ")\n",
    "\n",
    "elapsed_time = round(time.time() - start, 2)\n",
    "\n",
    "print(f\"\\nTiempo total de entrenamiento: {elapsed_time} segundos\")\n",
    "print(f\"\\nResultados de todos los modelos:\")\n",
    "for model_name, metrics in results.items():\n",
    "    print(f\"  {model_name}: RMSE={metrics['rmse']}, R2={metrics['r2']}\")\n",
    "\n",
    "print(f\"\\nüèÜ Mejor modelo: {best_model_name}\")\n",
    "print(f\"   RMSE: {results[best_model_name]['rmse']}\")\n",
    "print(f\"   R2: {results[best_model_name]['r2']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40d72e0e",
   "metadata": {},
   "source": [
    "# 4. Importamos Pipeline de preproc y Agregamos Modelo Ganador\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cb54aa32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-11-29 10:24:46.614\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mproduct_development.modeling.train\u001b[0m:\u001b[36mcreate_full_pipeline\u001b[0m:\u001b[36m325\u001b[0m - \u001b[1mCreando pipeline completo con modelo\u001b[0m\n",
      "Pipeline completo creado:\n",
      "  - cat_missing_imputation: SimpleCategoricalImputer\n",
      "  - num_median_imputation: MeanMedianImputer\n",
      "  - cat_freq_encoder: CountFrequencyEncoder\n",
      "  - dayofweek_mapper: Mapper\n",
      "  - feature_scaler: MinMaxScaler\n",
      "  - regressor: XGBRegressor\n"
     ]
    }
   ],
   "source": [
    "# 5. Crear pipeline completo con el mejor modelo\n",
    "full_pipeline = create_full_pipeline(preproc_pipeline, best_model)\n",
    "\n",
    "print(\"Pipeline completo creado:\")\n",
    "for step_name, step in full_pipeline.steps:\n",
    "    print(f\"  - {step_name}: {type(step).__name__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67418f39",
   "metadata": {},
   "source": [
    "# 5. Re entrenamos pipelines con el Modelo Ganador\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "290b75bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-11-29 10:24:46.740\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mproduct_development.modeling.train\u001b[0m:\u001b[36mtrain_final_model\u001b[0m:\u001b[36m357\u001b[0m - \u001b[1mEntrenando modelo final con dataset completo\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\fjgon\\OneDrive - Universidad Galileo\\Trimestre 8\\product_development\\notebooks\\..\\product_development\\transformers.py:135: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  X[var] = X[var].fillna(self.fill_value).astype(str)\n",
      "c:\\Users\\fjgon\\OneDrive - Universidad Galileo\\Trimestre 8\\product_development\\notebooks\\..\\product_development\\transformers.py:135: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  X[var] = X[var].fillna(self.fill_value).astype(str)\n",
      "c:\\Users\\fjgon\\OneDrive - Universidad Galileo\\Trimestre 8\\product_development\\notebooks\\..\\product_development\\transformers.py:135: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  X[var] = X[var].fillna(self.fill_value).astype(str)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-11-29 10:24:49.082\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mproduct_development.modeling.train\u001b[0m:\u001b[36mtrain_final_model\u001b[0m:\u001b[36m359\u001b[0m - \u001b[1mEntrenamiento del modelo final completado\u001b[0m\n",
      "Pipeline final entrenado correctamente.\n"
     ]
    }
   ],
   "source": [
    "# 6. Re-entrenar con el dataset completo\n",
    "X_full = dataset[FEATURES].copy()\n",
    "y_full = dataset[TARGET].copy()\n",
    "\n",
    "# Convertir tipos categ√≥ricos\n",
    "for col in CATEGORICAL_VARS:\n",
    "    X_full[col] = X_full[col].astype(\"O\")\n",
    "\n",
    "full_pipeline = train_final_model(full_pipeline, X_full, y_full)\n",
    "\n",
    "print(\"Pipeline final entrenado correctamente.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a8685697",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-11-29 10:24:49.102\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mproduct_development.modeling.train\u001b[0m:\u001b[36msave_pipeline\u001b[0m:\u001b[36m379\u001b[0m - \u001b[1mPipeline guardado en C:\\Users\\fjgon\\OneDrive - Universidad Galileo\\Trimestre 8\\product_development\\models\\sales_pipeline.pkl\u001b[0m\n",
      "Pipeline completo guardado en: C:\\Users\\fjgon\\OneDrive - Universidad Galileo\\Trimestre 8\\product_development\\models\\sales_pipeline.pkl\n"
     ]
    }
   ],
   "source": [
    "# 7. Guardar pipeline localmente\n",
    "save_pipeline(full_pipeline, PIPELINE_FILE)\n",
    "print(f\"Pipeline completo guardado en: {PIPELINE_FILE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cb9b9c5",
   "metadata": {},
   "source": [
    "# 8. Registro en MLflow Model Registry y Gesti√≥n Champion/Challenger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1ed8a312",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\fjgon\\OneDrive - Universidad Galileo\\Trimestre 8\\product_development\\notebooks\\..\\product_development\\transformers.py:135: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  X[var] = X[var].fillna(self.fill_value).astype(str)\n",
      "c:\\Users\\fjgon\\OneDrive - Universidad Galileo\\Trimestre 8\\product_development\\notebooks\\..\\product_development\\transformers.py:135: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  X[var] = X[var].fillna(self.fill_value).astype(str)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä M√©tricas finales del pipeline completo:\n",
      "   RMSE: 24.1248\n",
      "   MAE: 20.1097\n",
      "   R2: 0.0946\n",
      "   MSE: 582.0082\n"
     ]
    }
   ],
   "source": [
    "# 8.1 Calcular m√©tricas finales del pipeline completo\n",
    "if USE_MLFLOW:\n",
    "    # Predecir con el pipeline completo (usando datos sin transformar)\n",
    "    X_val_raw = dataset.iloc[int(len(dataset) * TRAIN_TEST_SPLIT_RATIO):][FEATURES].copy()\n",
    "    y_val_raw = dataset.iloc[int(len(dataset) * TRAIN_TEST_SPLIT_RATIO):][TARGET].copy()\n",
    "    \n",
    "    # Convertir tipos categ√≥ricos\n",
    "    for col in CATEGORICAL_VARS:\n",
    "        X_val_raw[col] = X_val_raw[col].astype(\"O\")\n",
    "    \n",
    "    y_pred_final = full_pipeline.predict(X_val_raw)\n",
    "    final_metrics = calculate_metrics(y_val_raw, y_pred_final)\n",
    "    \n",
    "    print(\"üìä M√©tricas finales del pipeline completo:\")\n",
    "    print(f\"   RMSE: {final_metrics['rmse']}\")\n",
    "    print(f\"   MAE: {final_metrics['mae']}\")\n",
    "    print(f\"   R2: {final_metrics['r2']}\")\n",
    "    print(f\"   MSE: {final_metrics['mse']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ace3382e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-11-29 10:24:49.448\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mproduct_development.modeling.train\u001b[0m:\u001b[36msetup_mlflow\u001b[0m:\u001b[36m155\u001b[0m - \u001b[1mMLflow configurado - Experimento: sales_prediction\u001b[0m\n",
      "\u001b[32m2025-11-29 10:24:49.489\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mproduct_development.modeling.train\u001b[0m:\u001b[36mcompare_with_champion\u001b[0m:\u001b[36m516\u001b[0m - \u001b[1mChampion rmse: 24.1248\u001b[0m\n",
      "\u001b[32m2025-11-29 10:24:49.489\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mproduct_development.modeling.train\u001b[0m:\u001b[36mcompare_with_champion\u001b[0m:\u001b[36m517\u001b[0m - \u001b[1mChallenger rmse: 24.1248\u001b[0m\n",
      "\n",
      "üìà Comparaci√≥n con el modelo Champion actual:\n",
      "   Champion RMSE: 24.1248\n",
      "   Challenger RMSE: 24.1248\n",
      "\n",
      "‚ö†Ô∏è El nuevo modelo NO supera al Champion actual\n"
     ]
    }
   ],
   "source": [
    "# 8.2 Comparar con el modelo Champion actual (si existe)\n",
    "if USE_MLFLOW:\n",
    "    is_better, champion_metrics = compare_with_champion(\n",
    "        final_metrics, \n",
    "        model_name=MLFLOW_MODEL_NAME,\n",
    "        metric_key=\"rmse\"\n",
    "    )\n",
    "    \n",
    "    if champion_metrics:\n",
    "        print(\"\\nüìà Comparaci√≥n con el modelo Champion actual:\")\n",
    "        print(f\"   Champion RMSE: {champion_metrics.get('rmse', 'N/A')}\")\n",
    "        print(f\"   Challenger RMSE: {final_metrics['rmse']}\")\n",
    "        \n",
    "        if is_better:\n",
    "            print(\"\\n‚úÖ El nuevo modelo es MEJOR que el Champion actual!\")\n",
    "        else:\n",
    "            print(\"\\n‚ö†Ô∏è El nuevo modelo NO supera al Champion actual\")\n",
    "    else:\n",
    "        print(\"\\nüìù No hay modelo Champion registrado. Este ser√° el primero.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "04fd0214",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/29 10:24:49 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-11-29 10:24:49.522\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mproduct_development.modeling.train\u001b[0m:\u001b[36msetup_mlflow\u001b[0m:\u001b[36m155\u001b[0m - \u001b[1mMLflow configurado - Experimento: sales_prediction\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/29 10:24:52 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "Registered model 'sales_prediction_model' already exists. Creating a new version of this model...\n",
      "Created version '2' of model 'sales_prediction_model'.\n",
      "c:\\Users\\fjgon\\OneDrive - Universidad Galileo\\Trimestre 8\\product_development\\notebooks\\..\\product_development\\modeling\\train.py:429: FutureWarning: ``mlflow.tracking.client.MlflowClient.get_latest_versions`` is deprecated since 2.9.0. Model registry stages will be removed in a future major release. To learn more about the deprecation of model registry stages, see our migration guide here: https://mlflow.org/docs/latest/model-registry.html#migrating-from-stages\n",
      "  latest_versions = client.get_latest_versions(model_name)\n",
      "Registered model 'sales_prediction_model' already exists. Creating a new version of this model...\n",
      "Created version '2' of model 'sales_prediction_model'.\n",
      "c:\\Users\\fjgon\\OneDrive - Universidad Galileo\\Trimestre 8\\product_development\\notebooks\\..\\product_development\\modeling\\train.py:429: FutureWarning: ``mlflow.tracking.client.MlflowClient.get_latest_versions`` is deprecated since 2.9.0. Model registry stages will be removed in a future major release. To learn more about the deprecation of model registry stages, see our migration guide here: https://mlflow.org/docs/latest/model-registry.html#migrating-from-stages\n",
      "  latest_versions = client.get_latest_versions(model_name)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-11-29 10:24:52.770\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mproduct_development.modeling.train\u001b[0m:\u001b[36mregister_model_to_mlflow\u001b[0m:\u001b[36m425\u001b[0m - \u001b[1mPipeline registrado en MLflow: models:/m-517d5d587e7a46c3a9edb9c8b5a8843a\u001b[0m\n",
      "\u001b[32m2025-11-29 10:24:52.800\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mproduct_development.modeling.train\u001b[0m:\u001b[36mregister_model_to_mlflow\u001b[0m:\u001b[36m433\u001b[0m - \u001b[1mModelo registrado como versi√≥n: 2\u001b[0m\n",
      "\u001b[32m2025-11-29 10:24:52.863\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mproduct_development.modeling.train\u001b[0m:\u001b[36mregister_model_to_mlflow\u001b[0m:\u001b[36m446\u001b[0m - \u001b[1mModelo versi√≥n 2 marcado como 'challenger'\u001b[0m\n",
      "\n",
      "ü•à Modelo registrado como CHALLENGER (versi√≥n 2)\n"
     ]
    }
   ],
   "source": [
    "# 8.3 Registrar modelo en MLflow Model Registry\n",
    "if USE_MLFLOW:\n",
    "    # Preparar input_example para la signature del modelo (muestra de datos sin transformar)\n",
    "    input_example_df = X_val_raw.head(5)\n",
    "    \n",
    "    # Decidir si registrar como champion o challenger\n",
    "    if champion_metrics is None or is_better:\n",
    "        # Primera vez o mejor que el champion -> registrar como champion\n",
    "        version = register_model_to_mlflow(\n",
    "            pipeline=full_pipeline,\n",
    "            model_name=MLFLOW_MODEL_NAME,\n",
    "            best_model_name=best_model_name,\n",
    "            metrics=final_metrics,\n",
    "            register_as_champion=True,\n",
    "            input_example=input_example_df\n",
    "        )\n",
    "        print(f\"\\nüèÜ Modelo registrado como CHAMPION (versi√≥n {version})\")\n",
    "    else:\n",
    "        # No es mejor -> registrar como challenger para comparaci√≥n futura\n",
    "        version = register_model_to_mlflow(\n",
    "            pipeline=full_pipeline,\n",
    "            model_name=MLFLOW_MODEL_NAME,\n",
    "            best_model_name=best_model_name,\n",
    "            metrics=final_metrics,\n",
    "            register_as_champion=False,\n",
    "            input_example=input_example_df\n",
    "        )\n",
    "        print(f\"\\nü•à Modelo registrado como CHALLENGER (versi√≥n {version})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fccb1349",
   "metadata": {},
   "source": [
    "# 9. Resumen del Experimento MLflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ad777f67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-11-29 10:24:52.883\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mproduct_development.modeling.train\u001b[0m:\u001b[36msetup_mlflow\u001b[0m:\u001b[36m155\u001b[0m - \u001b[1mMLflow configurado - Experimento: sales_prediction\u001b[0m\n",
      "üìã Resumen de todos los runs del experimento:\n",
      "   Total de runs: 10\n",
      "üìã Resumen de todos los runs del experimento:\n",
      "   Total de runs: 10\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "status",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "metrics.rmse",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "metrics.r2",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "349a03b9-d32e-4143-81aa-cf481bbdd4d2",
       "rows": [
        [
         "0",
         "FINISHED",
         "24.1248",
         "0.0946"
        ],
        [
         "1",
         "FINISHED",
         "26.9235",
         "0.2717"
        ],
        [
         "2",
         "FINISHED",
         "27.1293",
         "0.2605"
        ],
        [
         "3",
         "FINISHED",
         "27.4841",
         "0.2411"
        ],
        [
         "4",
         "FINISHED",
         "30.0452",
         "0.0931"
        ],
        [
         "5",
         "FINISHED",
         "24.1248",
         "0.0946"
        ],
        [
         "6",
         "FINISHED",
         "26.9235",
         "0.2717"
        ],
        [
         "7",
         "FINISHED",
         "27.1293",
         "0.2605"
        ],
        [
         "8",
         "FINISHED",
         "27.4841",
         "0.2411"
        ],
        [
         "9",
         "FINISHED",
         "30.0452",
         "0.0931"
        ]
       ],
       "shape": {
        "columns": 3,
        "rows": 10
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>status</th>\n",
       "      <th>metrics.rmse</th>\n",
       "      <th>metrics.r2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FINISHED</td>\n",
       "      <td>24.1248</td>\n",
       "      <td>0.0946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FINISHED</td>\n",
       "      <td>26.9235</td>\n",
       "      <td>0.2717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FINISHED</td>\n",
       "      <td>27.1293</td>\n",
       "      <td>0.2605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FINISHED</td>\n",
       "      <td>27.4841</td>\n",
       "      <td>0.2411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FINISHED</td>\n",
       "      <td>30.0452</td>\n",
       "      <td>0.0931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>FINISHED</td>\n",
       "      <td>24.1248</td>\n",
       "      <td>0.0946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>FINISHED</td>\n",
       "      <td>26.9235</td>\n",
       "      <td>0.2717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>FINISHED</td>\n",
       "      <td>27.1293</td>\n",
       "      <td>0.2605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>FINISHED</td>\n",
       "      <td>27.4841</td>\n",
       "      <td>0.2411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>FINISHED</td>\n",
       "      <td>30.0452</td>\n",
       "      <td>0.0931</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     status  metrics.rmse  metrics.r2\n",
       "0  FINISHED       24.1248      0.0946\n",
       "1  FINISHED       26.9235      0.2717\n",
       "2  FINISHED       27.1293      0.2605\n",
       "3  FINISHED       27.4841      0.2411\n",
       "4  FINISHED       30.0452      0.0931\n",
       "5  FINISHED       24.1248      0.0946\n",
       "6  FINISHED       26.9235      0.2717\n",
       "7  FINISHED       27.1293      0.2605\n",
       "8  FINISHED       27.4841      0.2411\n",
       "9  FINISHED       30.0452      0.0931"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 9.1 Obtener resumen de todos los experimentos\n",
    "if USE_MLFLOW:\n",
    "    experiment_df = get_experiment_summary(MLFLOW_EXPERIMENT_NAME)\n",
    "    \n",
    "    if not experiment_df.empty:\n",
    "        print(\"üìã Resumen de todos los runs del experimento:\")\n",
    "        print(f\"   Total de runs: {len(experiment_df)}\")\n",
    "        \n",
    "        # Mostrar las m√©tricas m√°s importantes\n",
    "        metric_cols = [col for col in experiment_df.columns if 'rmse' in col or 'r2' in col]\n",
    "        display_cols = ['run_name', 'status'] + metric_cols\n",
    "        available_cols = [col for col in display_cols if col in experiment_df.columns]\n",
    "        \n",
    "        display(experiment_df[available_cols].head(10))\n",
    "    else:\n",
    "        print(\"No hay runs registrados en el experimento\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4276726a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üì¶ Modelo: sales_prediction_model\n",
      "   Total de versiones: 2\n",
      "\n",
      "üèÜ Champion actual (versi√≥n 1):\n",
      "   RMSE: 24.1248\n",
      "   R2: 0.0946\n",
      "\n",
      "ü•à Challenger actual (versi√≥n 2):\n",
      "   RMSE: 24.1248\n",
      "   R2: 0.0946\n"
     ]
    }
   ],
   "source": [
    "# 9.2 Ver informaci√≥n del modelo registrado en Model Registry\n",
    "if USE_MLFLOW:\n",
    "    client = MlflowClient()\n",
    "    \n",
    "    try:\n",
    "        # Obtener todas las versiones del modelo\n",
    "        versions = client.search_model_versions(f\"name='{MLFLOW_MODEL_NAME}'\")\n",
    "        \n",
    "        print(f\"\\nüì¶ Modelo: {MLFLOW_MODEL_NAME}\")\n",
    "        print(f\"   Total de versiones: {len(versions)}\")\n",
    "        \n",
    "        # Mostrar informaci√≥n del champion actual\n",
    "        try:\n",
    "            champion_version = client.get_model_version_by_alias(MLFLOW_MODEL_NAME, MLFLOW_CHAMPION_ALIAS)\n",
    "            champion_run = client.get_run(champion_version.run_id)\n",
    "            print(f\"\\nüèÜ Champion actual (versi√≥n {champion_version.version}):\")\n",
    "            print(f\"   RMSE: {champion_run.data.metrics.get('rmse', 'N/A')}\")\n",
    "            print(f\"   R2: {champion_run.data.metrics.get('r2', 'N/A')}\")\n",
    "        except:\n",
    "            print(\"\\n   No hay modelo Champion asignado\")\n",
    "        \n",
    "        # Mostrar informaci√≥n del challenger actual\n",
    "        try:\n",
    "            challenger_version = client.get_model_version_by_alias(MLFLOW_MODEL_NAME, MLFLOW_CHALLENGER_ALIAS)\n",
    "            challenger_run = client.get_run(challenger_version.run_id)\n",
    "            print(f\"\\nü•à Challenger actual (versi√≥n {challenger_version.version}):\")\n",
    "            print(f\"   RMSE: {challenger_run.data.metrics.get('rmse', 'N/A')}\")\n",
    "            print(f\"   R2: {challenger_run.data.metrics.get('r2', 'N/A')}\")\n",
    "        except:\n",
    "            print(\"\\n   No hay modelo Challenger asignado\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error obteniendo informaci√≥n del modelo: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "14106038",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9.3 (Opcional) Promover Challenger a Champion manualmente\n",
    "# Descomenta las siguientes l√≠neas si deseas promover manualmente un challenger a champion\n",
    "\n",
    "# if USE_MLFLOW:\n",
    "#     success = promote_challenger_to_champion(model_name=MLFLOW_MODEL_NAME)\n",
    "#     if success:\n",
    "#         print(\"‚úÖ Challenger promovido a Champion exitosamente!\")\n",
    "#     else:\n",
    "#         print(\"‚ùå Error al promover Challenger\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5feb6289",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "üñ•Ô∏è  Para visualizar los experimentos en MLflow UI ejecuta:\n",
      "============================================================\n",
      "\n",
      "   mlflow ui --backend-store-uri mlruns\n",
      "\n",
      "   Luego abre en tu navegador: http://localhost:5000\n",
      "\n",
      "============================================================\n",
      "üìä En la UI podr√°s ver:\n",
      "   - Todos los experimentos y runs\n",
      "   - Comparaci√≥n de m√©tricas entre modelos\n",
      "   - Hiperpar√°metros de cada modelo\n",
      "   - Model Registry con versiones Champion/Challenger\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# 9.4 Instrucciones para visualizar MLflow UI\n",
    "print(\"=\" * 60)\n",
    "print(\"üñ•Ô∏è  Para visualizar los experimentos en MLflow UI ejecuta:\")\n",
    "print(\"=\" * 60)\n",
    "print(\"\\n   mlflow ui --backend-store-uri mlruns\")\n",
    "print(\"\\n   Luego abre en tu navegador: http://localhost:5000\")\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"üìä En la UI podr√°s ver:\")\n",
    "print(\"   - Todos los experimentos y runs\")\n",
    "print(\"   - Comparaci√≥n de m√©tricas entre modelos\")\n",
    "print(\"   - Hiperpar√°metros de cada modelo\")\n",
    "print(\"   - Model Registry con versiones Champion/Challenger\")\n",
    "print(\"=\" * 60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "product_development",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
