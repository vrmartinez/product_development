{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "417a4b12",
   "metadata": {},
   "source": [
    "# 1 Cargamos librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "15fe8baa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-11-29 12:33:44.845\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mproduct_development.config\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m17\u001b[0m - \u001b[1mPROJ_ROOT path is: C:\\Users\\fjgon\\OneDrive - Universidad Galileo\\Trimestre 8\\product_development\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Importaciones\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import joblib\n",
    "import mlflow\n",
    "from mlflow.tracking import MlflowClient\n",
    "\n",
    "from loguru import logger\n",
    "\n",
    "# Importar m√≥dulos del paquete product_development\n",
    "from product_development.config import (\n",
    "    TARGET, FEATURES, CATEGORICAL_VARS, RAW_DATA_DIR, MODELS_DIR,\n",
    "    FEATURE_PIPELINE_FILE, PIPELINE_FILE, TRAIN_TEST_SPLIT_RATIO, RANDOM_STATE,\n",
    "    MLFLOW_EXPERIMENT_NAME, MLFLOW_MODEL_NAME, MLFLOW_TRACKING_URI,\n",
    "    MLFLOW_CHAMPION_ALIAS, MLFLOW_CHALLENGER_ALIAS\n",
    ")\n",
    "from product_development.dataset import load_raw_data, prepare_dataset, temporal_train_test_split\n",
    "from product_development.features import load_feature_pipeline, transform_features\n",
    "from product_development.modeling.train import (\n",
    "    get_model_configurations, train_and_evaluate_models,\n",
    "    create_full_pipeline, train_final_model, save_pipeline,\n",
    "    setup_mlflow, register_model_to_mlflow, get_champion_model,\n",
    "    compare_with_champion, promote_challenger_to_champion, get_experiment_summary,\n",
    "    calculate_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67cd25ba",
   "metadata": {},
   "source": [
    "Configuraci√≥n de modelos, logging y rutas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d14a3a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-11-29 12:33:45.615\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mproduct_development.modeling.train\u001b[0m:\u001b[36msetup_mlflow\u001b[0m:\u001b[36m155\u001b[0m - \u001b[1mMLflow configurado - Experimento: sales_prediction\u001b[0m\n",
      "MLflow Experiment ID: 781360344278088554\n",
      "MLflow Tracking URI: mlruns\n",
      "\n",
      "Modo de entrenamiento: fast\n",
      "Total de modelos a evaluar: 4\n",
      "\n",
      "Modelos configurados:\n",
      "  - LinearRegression\n",
      "  - RandomForest\n",
      "  - GradientBoosting\n",
      "  - XGBoost\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\fjgon\\miniconda3\\envs\\product_development\\Lib\\site-packages\\mlflow\\tracking\\_tracking_service\\utils.py:140: FutureWarning: Filesystem tracking backend (e.g., './mlruns') is deprecated. Please switch to a database backend (e.g., 'sqlite:///mlflow.db'). For feedback, see: https://github.com/mlflow/mlflow/issues/18534\n",
      "  return FileStore(store_uri, store_uri)\n"
     ]
    }
   ],
   "source": [
    "# 2. Configuraci√≥n de modelos y MLflow\n",
    "# Modo: \"fast\" (r√°pido, 4 modelos) o \"full\" (completo, 15 modelos)\n",
    "TRAINING_MODE = \"fast\"  # Cambiar a \"full\" para evaluaci√≥n completa\n",
    "USE_MLFLOW = True  # Habilitar/deshabilitar tracking de MLflow\n",
    "\n",
    "# Configurar MLflow\n",
    "if USE_MLFLOW:\n",
    "    experiment_id = setup_mlflow(MLFLOW_EXPERIMENT_NAME, MLFLOW_TRACKING_URI)\n",
    "    print(f\"MLflow Experiment ID: {experiment_id}\")\n",
    "    print(f\"MLflow Tracking URI: {MLFLOW_TRACKING_URI}\")\n",
    "\n",
    "models_configurations = get_model_configurations(mode=TRAINING_MODE)\n",
    "\n",
    "print(f\"\\nModo de entrenamiento: {TRAINING_MODE}\")\n",
    "print(f\"Total de modelos a evaluar: {len(models_configurations)}\")\n",
    "print(\"\\nModelos configurados:\")\n",
    "for name in models_configurations.keys():\n",
    "    print(f\"  - {name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5dde955",
   "metadata": {},
   "source": [
    "# 3 Entrenamiento y seleccion de modelos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2354bb3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-11-29 12:33:45.627\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mproduct_development.dataset\u001b[0m:\u001b[36mload_raw_data\u001b[0m:\u001b[36m49\u001b[0m - \u001b[1mCargando datos crudos desde C:\\Users\\fjgon\\OneDrive - Universidad Galileo\\Trimestre 8\\product_development\\data\\raw\\train.csv\u001b[0m\n",
      "\u001b[32m2025-11-29 12:33:45.920\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mproduct_development.dataset\u001b[0m:\u001b[36mload_raw_data\u001b[0m:\u001b[36m51\u001b[0m - \u001b[1mCargados 913000 registros\u001b[0m\n",
      "\u001b[32m2025-11-29 12:33:45.920\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mproduct_development.dataset\u001b[0m:\u001b[36madd_temporal_features\u001b[0m:\u001b[36m69\u001b[0m - \u001b[1mAgregando caracter√≠sticas temporales\u001b[0m\n",
      "\u001b[32m2025-11-29 12:33:46.059\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mproduct_development.dataset\u001b[0m:\u001b[36mconvert_categorical_types\u001b[0m:\u001b[36m92\u001b[0m - \u001b[1mConvirtiendo columnas categ√≥ricas a tipo object\u001b[0m\n",
      "Total registros: 913000\n",
      "\u001b[32m2025-11-29 12:33:46.114\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mproduct_development.dataset\u001b[0m:\u001b[36mtemporal_train_test_split\u001b[0m:\u001b[36m140\u001b[0m - \u001b[1mDividiendo datos con 80% para entrenamiento\u001b[0m\n",
      "\u001b[32m2025-11-29 12:33:46.290\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mproduct_development.dataset\u001b[0m:\u001b[36mtemporal_train_test_split\u001b[0m:\u001b[36m151\u001b[0m - \u001b[1mTama√±o entrenamiento: 730400, Tama√±o prueba: 182600\u001b[0m\n",
      "Train: (730400, 5), Val: (182600, 5)\n",
      "\u001b[32m2025-11-29 12:33:46.310\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mproduct_development.features\u001b[0m:\u001b[36mload_feature_pipeline\u001b[0m:\u001b[36m172\u001b[0m - \u001b[1mCargando pipeline de caracter√≠sticas desde C:\\Users\\fjgon\\OneDrive - Universidad Galileo\\Trimestre 8\\product_development\\models\\feature_engineering_pipeline.pkl\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\fjgon\\OneDrive - Universidad Galileo\\Trimestre 8\\product_development\\notebooks\\..\\product_development\\transformers.py:135: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  X[var] = X[var].fillna(self.fill_value).astype(str)\n",
      "c:\\Users\\fjgon\\OneDrive - Universidad Galileo\\Trimestre 8\\product_development\\notebooks\\..\\product_development\\transformers.py:135: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  X[var] = X[var].fillna(self.fill_value).astype(str)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-11-29 12:33:47.336\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mproduct_development.features\u001b[0m:\u001b[36mtransform_features\u001b[0m:\u001b[36m126\u001b[0m - \u001b[1mTransformando 730400 registros\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\fjgon\\OneDrive - Universidad Galileo\\Trimestre 8\\product_development\\notebooks\\..\\product_development\\transformers.py:135: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  X[var] = X[var].fillna(self.fill_value).astype(str)\n",
      "c:\\Users\\fjgon\\OneDrive - Universidad Galileo\\Trimestre 8\\product_development\\notebooks\\..\\product_development\\transformers.py:135: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  X[var] = X[var].fillna(self.fill_value).astype(str)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-11-29 12:33:48.100\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mproduct_development.features\u001b[0m:\u001b[36mtransform_features\u001b[0m:\u001b[36m126\u001b[0m - \u001b[1mTransformando 182600 registros\u001b[0m\n",
      "Shape X_train_proc: (730400, 5)\n",
      "Shape X_val_proc: (182600, 5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\fjgon\\OneDrive - Universidad Galileo\\Trimestre 8\\product_development\\notebooks\\..\\product_development\\transformers.py:135: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  X[var] = X[var].fillna(self.fill_value).astype(str)\n",
      "c:\\Users\\fjgon\\OneDrive - Universidad Galileo\\Trimestre 8\\product_development\\notebooks\\..\\product_development\\transformers.py:135: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  X[var] = X[var].fillna(self.fill_value).astype(str)\n"
     ]
    }
   ],
   "source": [
    "# 3. Cargar y preparar datos usando los m√≥dulos del paquete\n",
    "raw_data = load_raw_data(RAW_DATA_DIR / \"train.csv\")\n",
    "dataset = prepare_dataset(raw_data)\n",
    "\n",
    "print(f\"Total registros: {len(dataset)}\")\n",
    "\n",
    "# Split temporal 80/20\n",
    "X_train, X_val, y_train, y_val = temporal_train_test_split(dataset, TRAIN_TEST_SPLIT_RATIO)\n",
    "\n",
    "print(f\"Train: {X_train.shape}, Val: {X_val.shape}\")\n",
    "\n",
    "# Cargar pipeline de preprocesamiento\n",
    "preproc_pipeline = load_feature_pipeline(FEATURE_PIPELINE_FILE)\n",
    "\n",
    "# Ajustar pipeline con datos de entrenamiento\n",
    "preproc_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Transformar datos\n",
    "X_train_proc = transform_features(preproc_pipeline, X_train)\n",
    "X_val_proc = transform_features(preproc_pipeline, X_val)\n",
    "\n",
    "print(f\"Shape X_train_proc: {X_train_proc.shape}\")\n",
    "print(f\"Shape X_val_proc: {X_val_proc.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "16a82774",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-11-29 12:33:51.104\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mproduct_development.modeling.train\u001b[0m:\u001b[36mtrain_and_evaluate_models\u001b[0m:\u001b[36m245\u001b[0m - \u001b[1mIniciando entrenamiento y evaluaci√≥n de modelos\u001b[0m\n",
      "\u001b[32m2025-11-29 12:33:51.118\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mproduct_development.modeling.train\u001b[0m:\u001b[36msetup_mlflow\u001b[0m:\u001b[36m155\u001b[0m - \u001b[1mMLflow configurado - Experimento: sales_prediction\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Entrenando modelos:   0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-11-29 12:33:51.120\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mproduct_development.modeling.train\u001b[0m:\u001b[36mtrain_and_evaluate_models\u001b[0m:\u001b[36m252\u001b[0m - \u001b[1mEntrenando modelo: LinearRegression\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Entrenando modelos:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  2.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-11-29 12:33:51.497\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mproduct_development.modeling.train\u001b[0m:\u001b[36mtrain_and_evaluate_models\u001b[0m:\u001b[36m281\u001b[0m - \u001b[1mModelo LinearRegression - RMSE: 30.0452, R2: 0.0931\u001b[0m\n",
      "\u001b[32m2025-11-29 12:33:51.504\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mproduct_development.modeling.train\u001b[0m:\u001b[36mtrain_and_evaluate_models\u001b[0m:\u001b[36m252\u001b[0m - \u001b[1mEntrenando modelo: RandomForest\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Entrenando modelos:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:04<00:05,  2.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-11-29 12:33:55.762\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mproduct_development.modeling.train\u001b[0m:\u001b[36mtrain_and_evaluate_models\u001b[0m:\u001b[36m281\u001b[0m - \u001b[1mModelo RandomForest - RMSE: 27.4841, R2: 0.2411\u001b[0m\n",
      "\u001b[32m2025-11-29 12:33:55.778\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mproduct_development.modeling.train\u001b[0m:\u001b[36mtrain_and_evaluate_models\u001b[0m:\u001b[36m252\u001b[0m - \u001b[1mEntrenando modelo: GradientBoosting\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Entrenando modelos:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:23<00:09,  9.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-11-29 12:34:14.275\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mproduct_development.modeling.train\u001b[0m:\u001b[36mtrain_and_evaluate_models\u001b[0m:\u001b[36m281\u001b[0m - \u001b[1mModelo GradientBoosting - RMSE: 27.1293, R2: 0.2605\u001b[0m\n",
      "\u001b[32m2025-11-29 12:34:14.289\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mproduct_development.modeling.train\u001b[0m:\u001b[36mtrain_and_evaluate_models\u001b[0m:\u001b[36m252\u001b[0m - \u001b[1mEntrenando modelo: XGBoost\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Entrenando modelos: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:24<00:00,  6.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-11-29 12:34:15.491\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mproduct_development.modeling.train\u001b[0m:\u001b[36mtrain_and_evaluate_models\u001b[0m:\u001b[36m281\u001b[0m - \u001b[1mModelo XGBoost - RMSE: 26.9235, R2: 0.2717\u001b[0m\n",
      "\u001b[32m2025-11-29 12:34:15.507\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mproduct_development.modeling.train\u001b[0m:\u001b[36mtrain_and_evaluate_models\u001b[0m:\u001b[36m301\u001b[0m - \u001b[1mMejor modelo: XGBoost con RMSE = 26.9235\u001b[0m\n",
      "\n",
      "Tiempo total de entrenamiento: 24.4 segundos\n",
      "\n",
      "Resultados de todos los modelos:\n",
      "  LinearRegression: RMSE=30.0452, R2=0.0931\n",
      "  RandomForest: RMSE=27.4841, R2=0.2411\n",
      "  GradientBoosting: RMSE=27.1293, R2=0.2605\n",
      "  XGBoost: RMSE=26.9235, R2=0.2717\n",
      "\n",
      "üèÜ Mejor modelo: XGBoost\n",
      "   RMSE: 26.9235\n",
      "   R2: 0.2717\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 4. Entrenamiento y evaluaci√≥n de modelos con MLflow tracking\n",
    "start = time.time()\n",
    "\n",
    "results, best_model_name, best_model = train_and_evaluate_models(\n",
    "    X_train_proc, y_train,\n",
    "    X_val_proc, y_val,\n",
    "    models_configurations,\n",
    "    use_mlflow=USE_MLFLOW\n",
    ")\n",
    "\n",
    "elapsed_time = round(time.time() - start, 2)\n",
    "\n",
    "print(f\"\\nTiempo total de entrenamiento: {elapsed_time} segundos\")\n",
    "print(f\"\\nResultados de todos los modelos:\")\n",
    "for model_name, metrics in results.items():\n",
    "    print(f\"  {model_name}: RMSE={metrics['rmse']}, R2={metrics['r2']}\")\n",
    "\n",
    "print(f\"\\nüèÜ Mejor modelo: {best_model_name}\")\n",
    "print(f\"   RMSE: {results[best_model_name]['rmse']}\")\n",
    "print(f\"   R2: {results[best_model_name]['r2']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40d72e0e",
   "metadata": {},
   "source": [
    "# 4. Importamos Pipeline de preproc y Agregamos Modelo Ganador\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cb54aa32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-11-29 12:34:21.192\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mproduct_development.modeling.train\u001b[0m:\u001b[36mcreate_full_pipeline\u001b[0m:\u001b[36m325\u001b[0m - \u001b[1mCreando pipeline completo con modelo\u001b[0m\n",
      "Pipeline completo creado:\n",
      "  - cat_missing_imputation: SimpleCategoricalImputer\n",
      "  - num_median_imputation: MeanMedianImputer\n",
      "  - cat_freq_encoder: CountFrequencyEncoder\n",
      "  - dayofweek_mapper: Mapper\n",
      "  - feature_scaler: MinMaxScaler\n",
      "  - regressor: XGBRegressor\n"
     ]
    }
   ],
   "source": [
    "# 5. Crear pipeline completo con el mejor modelo\n",
    "full_pipeline = create_full_pipeline(preproc_pipeline, best_model)\n",
    "\n",
    "print(\"Pipeline completo creado:\")\n",
    "for step_name, step in full_pipeline.steps:\n",
    "    print(f\"  - {step_name}: {type(step).__name__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67418f39",
   "metadata": {},
   "source": [
    "# 5. Re entrenamos pipelines con el Modelo Ganador\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "290b75bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-11-29 12:34:24.159\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mproduct_development.modeling.train\u001b[0m:\u001b[36mtrain_final_model\u001b[0m:\u001b[36m357\u001b[0m - \u001b[1mEntrenando modelo final con dataset completo\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\fjgon\\OneDrive - Universidad Galileo\\Trimestre 8\\product_development\\notebooks\\..\\product_development\\transformers.py:135: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  X[var] = X[var].fillna(self.fill_value).astype(str)\n",
      "c:\\Users\\fjgon\\OneDrive - Universidad Galileo\\Trimestre 8\\product_development\\notebooks\\..\\product_development\\transformers.py:135: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  X[var] = X[var].fillna(self.fill_value).astype(str)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-11-29 12:34:26.473\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mproduct_development.modeling.train\u001b[0m:\u001b[36mtrain_final_model\u001b[0m:\u001b[36m359\u001b[0m - \u001b[1mEntrenamiento del modelo final completado\u001b[0m\n",
      "Pipeline final entrenado correctamente.\n"
     ]
    }
   ],
   "source": [
    "# 6. Re-entrenar con el dataset completo\n",
    "X_full = dataset[FEATURES].copy()\n",
    "y_full = dataset[TARGET].copy()\n",
    "\n",
    "# Convertir tipos categ√≥ricos\n",
    "for col in CATEGORICAL_VARS:\n",
    "    X_full[col] = X_full[col].astype(\"O\")\n",
    "\n",
    "full_pipeline = train_final_model(full_pipeline, X_full, y_full)\n",
    "\n",
    "print(\"Pipeline final entrenado correctamente.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a8685697",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-11-29 12:34:28.446\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mproduct_development.modeling.train\u001b[0m:\u001b[36msave_pipeline\u001b[0m:\u001b[36m379\u001b[0m - \u001b[1mPipeline guardado en C:\\Users\\fjgon\\OneDrive - Universidad Galileo\\Trimestre 8\\product_development\\models\\sales_pipeline.pkl\u001b[0m\n",
      "Pipeline completo guardado en: C:\\Users\\fjgon\\OneDrive - Universidad Galileo\\Trimestre 8\\product_development\\models\\sales_pipeline.pkl\n"
     ]
    }
   ],
   "source": [
    "# 7. Guardar pipeline localmente\n",
    "save_pipeline(full_pipeline, PIPELINE_FILE)\n",
    "print(f\"Pipeline completo guardado en: {PIPELINE_FILE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cb9b9c5",
   "metadata": {},
   "source": [
    "# 8. Registro en MLflow Model Registry y Gesti√≥n Champion/Challenger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1ed8a312",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä M√©tricas finales del pipeline completo:\n",
      "   RMSE: 24.1248\n",
      "   MAE: 20.1097\n",
      "   R2: 0.0946\n",
      "   MSE: 582.0082\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\fjgon\\OneDrive - Universidad Galileo\\Trimestre 8\\product_development\\notebooks\\..\\product_development\\transformers.py:135: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  X[var] = X[var].fillna(self.fill_value).astype(str)\n",
      "c:\\Users\\fjgon\\OneDrive - Universidad Galileo\\Trimestre 8\\product_development\\notebooks\\..\\product_development\\transformers.py:135: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  X[var] = X[var].fillna(self.fill_value).astype(str)\n"
     ]
    }
   ],
   "source": [
    "# 8.1 Calcular m√©tricas finales del pipeline completo\n",
    "if USE_MLFLOW:\n",
    "    # Predecir con el pipeline completo (usando datos sin transformar)\n",
    "    X_val_raw = dataset.iloc[int(len(dataset) * TRAIN_TEST_SPLIT_RATIO):][FEATURES].copy()\n",
    "    y_val_raw = dataset.iloc[int(len(dataset) * TRAIN_TEST_SPLIT_RATIO):][TARGET].copy()\n",
    "    \n",
    "    # Convertir tipos categ√≥ricos\n",
    "    for col in CATEGORICAL_VARS:\n",
    "        X_val_raw[col] = X_val_raw[col].astype(\"O\")\n",
    "    \n",
    "    y_pred_final = full_pipeline.predict(X_val_raw)\n",
    "    final_metrics = calculate_metrics(y_val_raw, y_pred_final)\n",
    "    \n",
    "    print(\"üìä M√©tricas finales del pipeline completo:\")\n",
    "    print(f\"   RMSE: {final_metrics['rmse']}\")\n",
    "    print(f\"   MAE: {final_metrics['mae']}\")\n",
    "    print(f\"   R2: {final_metrics['r2']}\")\n",
    "    print(f\"   MSE: {final_metrics['mse']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ace3382e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-11-29 12:34:33.851\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mproduct_development.modeling.train\u001b[0m:\u001b[36msetup_mlflow\u001b[0m:\u001b[36m155\u001b[0m - \u001b[1mMLflow configurado - Experimento: sales_prediction\u001b[0m\n",
      "\u001b[32m2025-11-29 12:34:33.895\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mproduct_development.modeling.train\u001b[0m:\u001b[36mcompare_with_champion\u001b[0m:\u001b[36m533\u001b[0m - \u001b[1mChampion rmse: 24.1248\u001b[0m\n",
      "\u001b[32m2025-11-29 12:34:33.895\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mproduct_development.modeling.train\u001b[0m:\u001b[36mcompare_with_champion\u001b[0m:\u001b[36m534\u001b[0m - \u001b[1mChallenger rmse: 24.1248\u001b[0m\n",
      "\n",
      "üìà Comparaci√≥n con el modelo Champion actual:\n",
      "   Champion RMSE: 24.1248\n",
      "   Challenger RMSE: 24.1248\n",
      "\n",
      "‚ö†Ô∏è El nuevo modelo NO supera al Champion actual\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\fjgon\\miniconda3\\envs\\product_development\\Lib\\site-packages\\mlflow\\tracking\\_model_registry\\utils.py:215: FutureWarning: Filesystem model registry backend (e.g., './mlruns') is deprecated. Please switch to a database backend (e.g., 'sqlite:///mlflow.db'). For feedback, see: https://github.com/mlflow/mlflow/issues/18534\n",
      "  return FileStore(store_uri)\n"
     ]
    }
   ],
   "source": [
    "# 8.2 Comparar con el modelo Champion actual (si existe)\n",
    "if USE_MLFLOW:\n",
    "    is_better, champion_metrics = compare_with_champion(\n",
    "        final_metrics, \n",
    "        model_name=MLFLOW_MODEL_NAME,\n",
    "        metric_key=\"rmse\"\n",
    "    )\n",
    "    \n",
    "    if champion_metrics:\n",
    "        print(\"\\nüìà Comparaci√≥n con el modelo Champion actual:\")\n",
    "        print(f\"   Champion RMSE: {champion_metrics.get('rmse', 'N/A')}\")\n",
    "        print(f\"   Challenger RMSE: {final_metrics['rmse']}\")\n",
    "        \n",
    "        if is_better:\n",
    "            print(\"\\n‚úÖ El nuevo modelo es MEJOR que el Champion actual!\")\n",
    "        else:\n",
    "            print(\"\\n‚ö†Ô∏è El nuevo modelo NO supera al Champion actual\")\n",
    "    else:\n",
    "        print(\"\\nüìù No hay modelo Champion registrado. Este ser√° el primero.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "04fd0214",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-11-29 12:34:36.599\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mproduct_development.modeling.train\u001b[0m:\u001b[36msetup_mlflow\u001b[0m:\u001b[36m155\u001b[0m - \u001b[1mMLflow configurado - Experimento: sales_prediction\u001b[0m\n",
      "\u001b[32m2025-11-29 12:34:36.721\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mproduct_development.modeling.train\u001b[0m:\u001b[36mregister_model_to_mlflow\u001b[0m:\u001b[36m430\u001b[0m - \u001b[1mPipeline registrado en MLflow como artefacto\u001b[0m\n",
      "\u001b[32m2025-11-29 12:34:36.893\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mproduct_development.modeling.train\u001b[0m:\u001b[36mregister_model_to_mlflow\u001b[0m:\u001b[36m450\u001b[0m - \u001b[1mModelo registrado como versi√≥n: 5\u001b[0m\n",
      "\u001b[32m2025-11-29 12:34:36.970\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mproduct_development.modeling.train\u001b[0m:\u001b[36mregister_model_to_mlflow\u001b[0m:\u001b[36m463\u001b[0m - \u001b[1mModelo versi√≥n 5 marcado como 'challenger'\u001b[0m\n",
      "\n",
      "ü•à Modelo registrado como CHALLENGER (versi√≥n 5)\n"
     ]
    }
   ],
   "source": [
    "# 8.3 Registrar modelo en MLflow Model Registry\n",
    "if USE_MLFLOW:\n",
    "    # Preparar input_example para la signature del modelo (muestra de datos sin transformar)\n",
    "    input_example_df = X_val_raw.head(5)\n",
    "    \n",
    "    # Decidir si registrar como champion o challenger\n",
    "    if champion_metrics is None or is_better:\n",
    "        # Primera vez o mejor que el champion -> registrar como champion\n",
    "        version = register_model_to_mlflow(\n",
    "            pipeline=full_pipeline,\n",
    "            model_name=MLFLOW_MODEL_NAME,\n",
    "            best_model_name=best_model_name,\n",
    "            metrics=final_metrics,\n",
    "            register_as_champion=True,\n",
    "            input_example=input_example_df\n",
    "        )\n",
    "        print(f\"\\nüèÜ Modelo registrado como CHAMPION (versi√≥n {version})\")\n",
    "    else:\n",
    "        # No es mejor -> registrar como challenger para comparaci√≥n futura\n",
    "        version = register_model_to_mlflow(\n",
    "            pipeline=full_pipeline,\n",
    "            model_name=MLFLOW_MODEL_NAME,\n",
    "            best_model_name=best_model_name,\n",
    "            metrics=final_metrics,\n",
    "            register_as_champion=False,\n",
    "            input_example=input_example_df\n",
    "        )\n",
    "        print(f\"\\nü•à Modelo registrado como CHALLENGER (versi√≥n {version})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fccb1349",
   "metadata": {},
   "source": [
    "# 9. Resumen del Experimento MLflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ad777f67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-11-29 12:34:39.770\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mproduct_development.modeling.train\u001b[0m:\u001b[36msetup_mlflow\u001b[0m:\u001b[36m155\u001b[0m - \u001b[1mMLflow configurado - Experimento: sales_prediction\u001b[0m\n",
      "üìã Resumen de todos los runs del experimento:\n",
      "   Total de runs: 38\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "status",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "metrics.r2",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "metrics.rmse",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "d623b889-336b-4245-8478-91aa16d9e2dd",
       "rows": [
        [
         "0",
         "FINISHED",
         "0.0946",
         "24.1248"
        ],
        [
         "1",
         "FINISHED",
         "0.2717",
         "26.9235"
        ],
        [
         "2",
         "FINISHED",
         "0.2605",
         "27.1293"
        ],
        [
         "3",
         "FINISHED",
         "0.2411",
         "27.4841"
        ],
        [
         "4",
         "FINISHED",
         "0.0931",
         "30.0452"
        ],
        [
         "5",
         "FAILED",
         "-0.0051",
         "25.4187"
        ],
        [
         "6",
         "FAILED",
         "0.2717",
         "26.9235"
        ],
        [
         "7",
         "FAILED",
         "0.2605",
         "27.1293"
        ],
        [
         "8",
         "FAILED",
         "0.2411",
         "27.4841"
        ],
        [
         "9",
         "FAILED",
         "0.0931",
         "30.0452"
        ]
       ],
       "shape": {
        "columns": 3,
        "rows": 10
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>status</th>\n",
       "      <th>metrics.r2</th>\n",
       "      <th>metrics.rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FINISHED</td>\n",
       "      <td>0.0946</td>\n",
       "      <td>24.1248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FINISHED</td>\n",
       "      <td>0.2717</td>\n",
       "      <td>26.9235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FINISHED</td>\n",
       "      <td>0.2605</td>\n",
       "      <td>27.1293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FINISHED</td>\n",
       "      <td>0.2411</td>\n",
       "      <td>27.4841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FINISHED</td>\n",
       "      <td>0.0931</td>\n",
       "      <td>30.0452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>FAILED</td>\n",
       "      <td>-0.0051</td>\n",
       "      <td>25.4187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>FAILED</td>\n",
       "      <td>0.2717</td>\n",
       "      <td>26.9235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>FAILED</td>\n",
       "      <td>0.2605</td>\n",
       "      <td>27.1293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>FAILED</td>\n",
       "      <td>0.2411</td>\n",
       "      <td>27.4841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>FAILED</td>\n",
       "      <td>0.0931</td>\n",
       "      <td>30.0452</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     status  metrics.r2  metrics.rmse\n",
       "0  FINISHED      0.0946       24.1248\n",
       "1  FINISHED      0.2717       26.9235\n",
       "2  FINISHED      0.2605       27.1293\n",
       "3  FINISHED      0.2411       27.4841\n",
       "4  FINISHED      0.0931       30.0452\n",
       "5    FAILED     -0.0051       25.4187\n",
       "6    FAILED      0.2717       26.9235\n",
       "7    FAILED      0.2605       27.1293\n",
       "8    FAILED      0.2411       27.4841\n",
       "9    FAILED      0.0931       30.0452"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 9.1 Obtener resumen de todos los experimentos\n",
    "if USE_MLFLOW:\n",
    "    experiment_df = get_experiment_summary(MLFLOW_EXPERIMENT_NAME)\n",
    "    \n",
    "    if not experiment_df.empty:\n",
    "        print(\"üìã Resumen de todos los runs del experimento:\")\n",
    "        print(f\"   Total de runs: {len(experiment_df)}\")\n",
    "        \n",
    "        # Mostrar las m√©tricas m√°s importantes\n",
    "        metric_cols = [col for col in experiment_df.columns if 'rmse' in col or 'r2' in col]\n",
    "        display_cols = ['run_name', 'status'] + metric_cols\n",
    "        available_cols = [col for col in display_cols if col in experiment_df.columns]\n",
    "        \n",
    "        display(experiment_df[available_cols].head(10))\n",
    "    else:\n",
    "        print(\"No hay runs registrados en el experimento\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4276726a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üì¶ Modelo: sales_prediction_model\n",
      "   Total de versiones: 5\n",
      "\n",
      "üèÜ Champion actual (versi√≥n 1):\n",
      "   RMSE: 24.1248\n",
      "   R2: 0.0946\n",
      "\n",
      "ü•à Challenger actual (versi√≥n 5):\n",
      "   RMSE: 24.1248\n",
      "   R2: 0.0946\n"
     ]
    }
   ],
   "source": [
    "# 9.2 Ver informaci√≥n del modelo registrado en Model Registry\n",
    "if USE_MLFLOW:\n",
    "    client = MlflowClient()\n",
    "    \n",
    "    try:\n",
    "        # Obtener todas las versiones del modelo\n",
    "        versions = client.search_model_versions(f\"name='{MLFLOW_MODEL_NAME}'\")\n",
    "        \n",
    "        print(f\"\\nüì¶ Modelo: {MLFLOW_MODEL_NAME}\")\n",
    "        print(f\"   Total de versiones: {len(versions)}\")\n",
    "        \n",
    "        # Mostrar informaci√≥n del champion actual\n",
    "        try:\n",
    "            champion_version = client.get_model_version_by_alias(MLFLOW_MODEL_NAME, MLFLOW_CHAMPION_ALIAS)\n",
    "            champion_run = client.get_run(champion_version.run_id)\n",
    "            print(f\"\\nüèÜ Champion actual (versi√≥n {champion_version.version}):\")\n",
    "            print(f\"   RMSE: {champion_run.data.metrics.get('rmse', 'N/A')}\")\n",
    "            print(f\"   R2: {champion_run.data.metrics.get('r2', 'N/A')}\")\n",
    "        except:\n",
    "            print(\"\\n   No hay modelo Champion asignado\")\n",
    "        \n",
    "        # Mostrar informaci√≥n del challenger actual\n",
    "        try:\n",
    "            challenger_version = client.get_model_version_by_alias(MLFLOW_MODEL_NAME, MLFLOW_CHALLENGER_ALIAS)\n",
    "            challenger_run = client.get_run(challenger_version.run_id)\n",
    "            print(f\"\\nü•à Challenger actual (versi√≥n {challenger_version.version}):\")\n",
    "            print(f\"   RMSE: {challenger_run.data.metrics.get('rmse', 'N/A')}\")\n",
    "            print(f\"   R2: {challenger_run.data.metrics.get('r2', 'N/A')}\")\n",
    "        except:\n",
    "            print(\"\\n   No hay modelo Challenger asignado\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error obteniendo informaci√≥n del modelo: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "14106038",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9.3 (Opcional) Promover Challenger a Champion manualmente\n",
    "# Descomenta las siguientes l√≠neas si deseas promover manualmente un challenger a champion\n",
    "\n",
    "# if USE_MLFLOW:\n",
    "#     success = promote_challenger_to_champion(model_name=MLFLOW_MODEL_NAME)\n",
    "#     if success:\n",
    "#         print(\"‚úÖ Challenger promovido a Champion exitosamente!\")\n",
    "#     else:\n",
    "#         print(\"‚ùå Error al promover Challenger\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5feb6289",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "üñ•Ô∏è  Para visualizar los experimentos en MLflow UI ejecuta:\n",
      "============================================================\n",
      "\n",
      "   mlflow ui --backend-store-uri mlruns\n",
      "\n",
      "   Luego abre en tu navegador: http://localhost:5000\n",
      "\n",
      "============================================================\n",
      "üìä En la UI podr√°s ver:\n",
      "   - Todos los experimentos y runs\n",
      "   - Comparaci√≥n de m√©tricas entre modelos\n",
      "   - Hiperpar√°metros de cada modelo\n",
      "   - Model Registry con versiones Champion/Challenger\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# 9.4 Instrucciones para visualizar MLflow UI\n",
    "print(\"=\" * 60)\n",
    "print(\"üñ•Ô∏è  Para visualizar los experimentos en MLflow UI ejecuta:\")\n",
    "print(\"=\" * 60)\n",
    "print(\"\\n   mlflow ui --backend-store-uri mlruns\")\n",
    "print(\"\\n   Luego abre en tu navegador: http://localhost:5000\")\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"üìä En la UI podr√°s ver:\")\n",
    "print(\"   - Todos los experimentos y runs\")\n",
    "print(\"   - Comparaci√≥n de m√©tricas entre modelos\")\n",
    "print(\"   - Hiperpar√°metros de cada modelo\")\n",
    "print(\"   - Model Registry con versiones Champion/Challenger\")\n",
    "print(\"=\" * 60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "product_development",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
